{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=140)\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "\n",
    "MNIST_URL = \"https://github.com/MrHeadbang/machineLearning/raw/main/mnist.zip\"\n",
    "path_data = Path(\"data\")\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_zip = path_data / \"mnist.zip\"\n",
    "\n",
    "if not path_zip.exists(): \n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(MNIST_URL, path_zip)\n",
    "\n",
    "with gzip.open(path_zip) as f: \n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = pickle.load(f, encoding=\"latin-1\")\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = map(tensor, (x_train, y_train, x_val, y_val, x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 50\n",
    "\n",
    "w1 = torch.randn(m, nh)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh, 1)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b): return x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  2.40,   5.29,  -9.52,  11.67, -11.20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lin(x_train, w1, b1)\n",
    "print(t.shape)\n",
    "t[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.40,  5.29,  0.00, 11.67,  0.00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(t)\n",
    "t[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l1 = relu(l1)\n",
    "    l2 = lin(l1, w2, b2)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  8.88],\n",
       "        [-58.29],\n",
       "        [ -8.12],\n",
       "        [-33.32],\n",
       "        [ -1.84]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model(x_train)\n",
    "print(res.shape)\n",
    "res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 1]), torch.Size([50000]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds, y): return ((preds.squeeze() - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1495.67)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(res, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.500000000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(0.1*x for x in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.36)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(tensor(4.5), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 4, 1, 9])\n",
      "tensor([-0.50,  4.50,  0.50,  3.50, -4.50])\n",
      "tensor([ 0.25, 20.25,  0.25, 12.25, 20.25])\n",
      "tensor(10.65)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])\n",
    "print(tensor(4.5) - y_train[:5])\n",
    "print((tensor(4.5) - y_train[:5])**2)\n",
    "print(((tensor(4.5) - y_train[:5])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train.float(), 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, diff\n",
    "x, y = symbols(\"x, y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2*x, 6*x, x**3 + 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(x**2, x), diff(3*x**2 + 9, x), diff((x**3+1)*y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lingrad(inp, out, w, b):\n",
    "    inp.g = out.g @ w.T\n",
    "    w.g = inp.T @ out.g\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    l1 = lin(inp, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    out = lin(l2, w2, b2)\n",
    "    diff = out.squeeze() - targ\n",
    "    loss = (diff**2).mean()\n",
    "\n",
    "    loss.g = 1.0\n",
    "    diff.g = loss.g * (2.0*diff/diff.nelement()).unsqueeze(-1)\n",
    "    out.g = diff.g * 1.0\n",
    "    lingrad(l2, out, w2, b2)\n",
    "    l1.g = l2.g * (l1 > 0.0)\n",
    "    lingrad(inp, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad(x): return x.g.clone()\n",
    "chks = w1, w2, b1, b2, x_train\n",
    "grads = w1g, w2g, b1g, b2g, ig = tuple(map(get_grad, chks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkgrad(x): return x.clone().requires_grad_(True)\n",
    "ptgrads = pw1, pw2, pb1, pb2, px = tuple(map(mkgrad, chks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    l1 = lin(inp, pw1, pb1)\n",
    "    l1 = relu(l1)\n",
    "    l2 = lin(l1, pw2, pb2)\n",
    "    return mse(l2, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = forward(px, y_train)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "for i, a, b in zip(range(len(grads)), grads, ptgrads): \n",
    "    test_close(a, b.grad, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.0)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self): \n",
    "        self.inp.g = (self.inp > 0.0) * self.out.g\n",
    "\n",
    "class Lin:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "    \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = lin(inp, self.w, self.b)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.T\n",
    "        self.w.g = self.inp.T @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "\n",
    "class MSE:\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        self.out = mse(inp, targ)\n",
    "\n",
    "    def backward(self):\n",
    "        self.inp.g = 2.0 * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = MSE()\n",
    "\n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)\n",
    "loss = model(x_train, y_train)\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(w2g, w2.g, eps=0.01)\n",
    "test_close(b2g, b2.g, eps=0.01)\n",
    "test_close(w1g, w1.g, eps=0.01)\n",
    "test_close(b1g, b1.g, eps=0.01)\n",
    "test_close(ig, x_train.g, eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __call__(self, inp, *args):\n",
    "        self.inp = inp\n",
    "        self.args = args\n",
    "        self.out = self.forward()\n",
    "        return self.out\n",
    "\n",
    "    def forward(self): assert False\n",
    "    def backward(self): assert False\n",
    "\n",
    "class Lin(Module):\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def forward(self):\n",
    "        return self.inp@self.w + self.b\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.T\n",
    "        self.w.g = self.inp.T @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "\n",
    "class Relu(Module):\n",
    "    def forward(self): \n",
    "        return self.inp.clamp_min(0.)\n",
    "    \n",
    "    def backward(self): \n",
    "        self.inp.g = self.out.g * (self.inp > 0.0)\n",
    "\n",
    "class Mse(Module):\n",
    "    def forward (self):\n",
    "        targ = self.args[0]\n",
    "        return ((self.inp.squeeze() - targ)**2).mean()\n",
    "    \n",
    "    def backward(self): \n",
    "        targ = self.args[0]\n",
    "        self.inp.g = 2.0 * (self.inp.squeeze() - targ).unsqueeze(-1) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)\n",
    "loss = model(x_train, y_train)\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(w2g, w2.g, eps=0.01)\n",
    "test_close(b2g, b2.g, eps=0.01)\n",
    "test_close(w1g, w1.g, eps=0.01)\n",
    "test_close(b1g, b1.g, eps=0.01)\n",
    "test_close(ig, x_train.g, eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.w = torch.randn(n_in, n_out).requires_grad_()\n",
    "        self.b = torch.zeros(n_out).requires_grad_()\n",
    "\n",
    "    def forward(self, inp): \n",
    "        return inp@self.w + self.b\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [Linear(n_in, nh), nn.ReLU(), Linear(nh, n_out)]\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return F.mse_loss(x, targ.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)\n",
    "loss = model(x_train.float(), y_train.float())\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -9.97, -30.55, -20.10,  26.93,   1.61, -58.65,  52.14,   1.65,  32.30, -14.58,  -2.72,  14.98, -29.37,  17.35, -30.62,  70.68,\n",
       "          2.19, -15.31,   1.41,  70.35,  19.27,  28.08,   6.54, -38.02, -11.55,   5.50,  10.73,  96.44,  18.86,  -5.75,  37.09,  43.77,\n",
       "         35.34, -74.47,  90.89, -59.05,  49.98,   2.19,  37.49,  28.30,  -2.21, -13.69,  40.10,   4.89,  26.56, -13.67,   1.69,  35.08,\n",
       "        -50.73, -26.81])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0 = model.layers[0]\n",
    "l0.b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
