# Autogenerated! Edit minai_nbs/data.ipynb instead

import threading
import queue
import os
import math

import datasets as hfds

from minai.sampler import chunkify, Sampler, SamplerIter, SIO
from minai.datasets import SimpleDataset

class CMTO: # CollatorMTOpts
    def __init__(self, 
                 sampler_iter: SamplerIter = None, 
                 getitem_func=None, 
                 collate_func=None, 
                 num_workers=os.cpu_count(), 
                 max_available_batches=2, 
                 chunk_size_per_thread=4,
                 is_hf_ds=False):
        
        self.sampler_iter = sampler_iter
        self.getitem_func = getitem_func
        self.collate_func = collate_func
        self.num_workers = num_workers
        self.max_available_batches = max_available_batches
        self.chunk_size_per_thread = chunk_size_per_thread
        self.is_hf_ds = is_hf_ds

        # Extra special flags, gotta be set very manually
        self.COLLATOR_DEBUG = False
        self.WORKERS_DEBUG = False

    def __repr__(self):
        return f"CMTO({self.sampler_iter.opts},\n"\
            f"  getitem_func={self.getitem_func.__qualname__},\n"\
            f"  collate_func={self.collate_func.__qualname__},\n"\
            f"  num_workers={self.num_workers},\n"\
            f"  max_available_batches={self.max_available_batches},\n"\
            f"  chunk_size_per_thread={self.chunk_size_per_thread},\n"\
            f"  is_hf_ds={self.is_hf_ds})"


class CollatorCTX: # Internal
    def __init__(self, opts: CMTO, work_chunk_size):
        self.DEBUG = opts.WORKERS_DEBUG

        self.sampler_iter = opts.sampler_iter
        self.getitem_func = opts.getitem_func
        self.collate_func = opts.collate_func
        self.max_available_batches = opts.max_available_batches
        self.is_hf_ds = opts.is_hf_ds
        self.work_chunk_size = work_chunk_size

        self.workers = []
        self.indices_queue = queue.SimpleQueue()
        self.results_queue = queue.SimpleQueue()
        
        self.request_batch_event = threading.BoundedSemaphore(self.max_available_batches)
        self.collated_batches = queue.SimpleQueue()
        self.exit_requested = False

        for _ in range(self.max_available_batches): self.request_batch_event.acquire()


def threadproc_worker(ctx: CollatorCTX):
    while 1:
        indices = ctx.indices_queue.get()
        if indices is None: break
        work_ind, indices = indices

        if ctx.is_hf_ds:
            results = ctx.getitem_func(indices)
        else:
            results = [ctx.getitem_func(i) for i in indices]

        ctx.results_queue.put((work_ind, results))
        del results

def threadproc_collator(ctx: CollatorCTX):
    while 1:
        if ctx.DEBUG: print("batches top")
        
        ctx.request_batch_event.acquire()
        if ctx.exit_requested: break
        
        if ctx.DEBUG: print("batches start")
        for batch in ctx.sampler_iter:
            work_chunks = chunkify(batch, ctx.work_chunk_size)
            if ctx.DEBUG: print("will queue", len(work_chunks))
            for ind, work_chunk in enumerate(work_chunks):
                if ctx.DEBUG: print(ind, "put", len(work_chunk), work_chunk)
                ctx.indices_queue.put((ind, work_chunk))

            work_chunks_results = []
            for _ in range(len(work_chunks)):
                ind, results = ctx.results_queue.get()
                if ctx.DEBUG: print(ind, "got", len(results), results)
                work_chunks_results.append((ind, results))

            work_chunks_results.sort(key=lambda x: x[0])

            sorted_work_chunks_results = []
            if ctx.is_hf_ds: # SOA
                sorted_work_chunks_results = [x[1] for x in work_chunks_results]
            else:
                for work_chunk_result in work_chunks_results: # AOS
                    sorted_work_chunks_results.extend(work_chunk_result[1])
            
            del work_chunks_results

            ctx.collated_batches.put(ctx.collate_func(sorted_work_chunks_results))
            ctx.request_batch_event.acquire()
            if ctx.exit_requested: break # Double break

        if ctx.exit_requested: break # Double break
        if ctx.DEBUG: print("batches done")
        for _ in range(ctx.max_available_batches-1): ctx.request_batch_event.acquire()
        ctx.collated_batches.put(None)

    #if ctx.DEBUG: print("collator exit")


class CollatorMT:
    def __init__(self, collatormt_opts: CMTO):
        self.DEBUG = collatormt_opts.COLLATOR_DEBUG
        self.opts = collatormt_opts

        batch_size = self.opts.sampler_iter.opts.batch_size
        chunk_size_per_thread = self.opts.chunk_size_per_thread
        num_workers = self.opts.num_workers
        work_chunk_size = max(chunk_size_per_thread, 
                              batch_size // (num_workers * chunk_size_per_thread))

        new_num_workers = min(max(1, math.ceil(batch_size / work_chunk_size)), num_workers)
        if new_num_workers != num_workers:
            print(f"Number of workers reduced from {num_workers} to {new_num_workers}, since "\
                  f"num_workers*work_chunk_size > batch_size ({num_workers}*{work_chunk_size} > {batch_size})")
            self.opts.num_workers = new_num_workers

        self.ctx = CollatorCTX(self.opts, work_chunk_size)

        threading.Thread(target=threadproc_collator, args=(self.ctx,)).start()
        for _ in range(self.opts.num_workers): threading.Thread(target=threadproc_worker, args=(self.ctx,)).start()

    def __del__(self):
        self.ctx.exit_requested = True
        self.ctx.request_batch_event.release()

        for _ in range(self.opts.num_workers): self.ctx.indices_queue.put(None)

    def __iter__(self):
        self.ctx.request_batch_event.release(self.ctx.max_available_batches)
        
        while 1:
            if self.DEBUG: print("-> iter request")
            collated = self.ctx.collated_batches.get()
            if collated is None: 
                if self.DEBUG: print("-> iter done")
                break

            if self.DEBUG: print("-> iter got")

            yield collated
            self.ctx.request_batch_event.release()

def simple_collate_func(results):
    xs = [r[0] for r in results]
    ys = [r[1] for r in results]
    return xs, ys

def hf_first_ds(dsd):
    return next(iter(dsd.values()))

class HFCollate:
    def __init__(self, ds: hfds.Dataset):
        if type(ds) is hfds.DatasetDict: ds = hf_first_ds(ds)
        self.features = ds.features.keys()
        self.features_len = len(self.features)

    def __call__(self, results):
        collated = [[] for _ in range(self.features_len)]
        for result in results:
            for i, feature in enumerate(self.features):
                collated[i].extend(result[feature])
        return collated
    
    def __repr__(self):
        return f"CollateHF(features={list(self.features)})"

class DataLoader:
    def __init__(self, dataset, collatormt_opts:CMTO):
        self.dataset = dataset
        self.collator = CollatorMT(collatormt_opts)

    @classmethod
    def simple(cls, simple_ds: SimpleDataset, 
               sampler_iter_opts: SIO = None, 
               collatormt_opts: CMTO = None):
        sampler_iter_opts = sampler_iter_opts or SIO()
        collatormt_opts = collatormt_opts or CMTO()

        opts = collatormt_opts
        opts.sampler_iter = Sampler(len(simple_ds)).iter(sampler_iter_opts)
        opts.getitem_func = simple_ds.__getitem__
        opts.collate_func = simple_collate_func
        return cls(simple_ds, opts)

    @classmethod
    def hf(cls, hf_ds: hfds.Dataset,
           sampler_iter_opts: SIO = None, 
           collatormt_opts: CMTO = None):
        assert type(hf_ds) is hfds.Dataset, "Dataset expected (not DatasetDict)"
        sampler_iter_opts = sampler_iter_opts or SIO()
        collatormt_opts = collatormt_opts or CMTO()

        opts = collatormt_opts
        opts.sampler_iter = Sampler(len(hf_ds)).iter(sampler_iter_opts)
        opts.getitem_func = hf_ds.__getitem__
        opts.collate_func = HFCollate(hf_ds).__call__
        opts.is_hf_ds = True
        return cls(hf_ds, opts)
        
    def __iter__(self):
        yield from self.collator

    def __repr__(self):
        ctmo = self.collator.opts.__repr__()
        ctmo = ctmo.replace("\n", "\n  ")

        return f"DataLoader(ds={self.dataset},\n  {ctmo})"

