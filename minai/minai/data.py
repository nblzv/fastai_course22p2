# Autogenerated! Edit minai_nbs/data.ipynb instead

from minai.sampler import chunkify, Sampler, SamplerIter

import threading
import queue
import os
import math
class CollatorCTX:
    def __init__(self, sampler_iter, work_chunk_size, getitem_func, collate_func, max_available_batches):
        self.DEBUG = 0
        self.exit_requested = False

        self.sampler_iter = sampler_iter
        self.work_chunk_size = work_chunk_size
        self.collate_func = collate_func
        self.max_available_batches = max_available_batches

        self.request_batch_event = threading.BoundedSemaphore(self.max_available_batches)
        self.collated_batches = queue.SimpleQueue()

        self.workers = []
        self.getitem_func = getitem_func
        self.indices_queue = queue.SimpleQueue()
        self.results_queue = queue.SimpleQueue()

        for _ in range(self.max_available_batches): self.request_batch_event.acquire()
        

def threadproc_worker(ctx: CollatorCTX):
    while 1:
        indices = ctx.indices_queue.get()
        if indices is None: break
        work_ind, indices = indices

        results = [ctx.getitem_func(i) for i in indices]
        ctx.results_queue.put((work_ind, results))
        del results

def threadproc_collator(ctx: CollatorCTX):
    while 1:
        if ctx.DEBUG: print("batches top")
        ctx.request_batch_event.acquire()
        if ctx.exit_requested: break
        if ctx.DEBUG: print("batches start")

        for batch in ctx.sampler_iter:
            work_chunks = chunkify(batch, ctx.work_chunk_size)
            if ctx.DEBUG: print("will queue", len(work_chunks))
            for ind, work_chunk in enumerate(work_chunks):
                if ctx.DEBUG: print("put", len(work_chunk), work_chunk)
                ctx.indices_queue.put((ind, work_chunk))

            work_chunks_results = []
            for _ in range(len(work_chunks)):
                ind, results = ctx.results_queue.get()
                if ctx.DEBUG: print("got", len(results), results)
                work_chunks_results.append((ind, results))

            sorted_work_chunks_results = []
            work_chunks_results.sort(key=lambda x: x[0])
            for work_chunk_result in work_chunks_results:
                sorted_work_chunks_results.extend(work_chunk_result[1])

            if ctx.DEBUG: print("collating", len(sorted_work_chunks_results), sorted_work_chunks_results)
            ctx.collated_batches.put(ctx.collate_func(sorted_work_chunks_results))
            ctx.request_batch_event.acquire()

        if ctx.DEBUG: print("batches done")
        for _ in range(ctx.max_available_batches-1): ctx.request_batch_event.acquire()
        ctx.collated_batches.put(None)


class CollatorMT:
    def __init__(self, sampler_iter: SamplerIter, getitem_func, collate_func, *, num_workers=os.cpu_count(), max_available_batches=2, chunk_size_per_thread=4):
        self.DEBUG = 0

        work_chunk_size = max(4, sampler_iter.batch_size // (num_workers * chunk_size_per_thread))
        if work_chunk_size * num_workers > sampler_iter.batch_size:
            new_num_workers = max(1, math.ceil(sampler_iter.batch_size / work_chunk_size))
            print(f"Number of workers reduced from {num_workers} to {new_num_workers}, since num_workers*work_chunk_size > batch_size ({num_workers}*{work_chunk_size} > {sampler_iter.batch_size})")
            num_workers = new_num_workers

        self.num_workers = num_workers
        self.ctx = CollatorCTX(sampler_iter, work_chunk_size, getitem_func, collate_func, max_available_batches)

        threading.Thread(target=threadproc_collator, args=(self.ctx,)).start()
        for _ in range(num_workers): threading.Thread(target=threadproc_worker, args=(self.ctx,)).start()

    def __del__(self):
        self.ctx.exit_requested = True
        self.ctx.request_batch_event.release()

        for _ in range(self.num_workers): self.ctx.indices_queue.put(None)

    def __iter__(self):
        self.ctx.request_batch_event.release(self.ctx.max_available_batches)
        
        while 1:
            if self.DEBUG: print("-> iter request")
            collated = self.ctx.collated_batches.get()
            if collated is None: 
                if self.DEBUG: print("-> iter done")
                break

            if self.DEBUG: print("-> iter got")

            yield collated
            self.ctx.request_batch_event.release()
            
class Dataset:
    def __init__(self, xs, ys):
        self.xs = xs
        self.ys = ys
        assert len(xs) == len(ys)

    def __len__(self):
        return len(self.xs)
    
    def __getitem__(self, i):
        assert type(i) is int
        return self.xs[i], self.ys[i]
    
class DataLoader:
    def __init__(self, dataset, batch_size, shuffle, collate_func, **kwargs):
        self.sampler_iter = Sampler(len(dataset)).iter(batch_size, shuffle)
        self.collator = CollatorMT(self.sampler_iter, dataset.__getitem__, collate_func, **kwargs)

    def __iter__(self):
        yield from self.collator
