{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "import threading\n",
    "import queue\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import datasets as hfds\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.io as TFIO\n",
    "\n",
    "import minai.sampler as mins\n",
    "import minai.datasets as minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def simple_collate_func(array_of_results):\n",
    "    xs = [r[0] for results in array_of_results for r in results]\n",
    "    ys = [r[1] for results in array_of_results for r in results]\n",
    "    return xs, ys\n",
    "\n",
    "class HFCollate:\n",
    "    def __init__(self, ds: hfds.Dataset):\n",
    "        self.features = tuple(ds.features.keys())\n",
    "\n",
    "    def __call__(self, array_of_results):\n",
    "        collated = [[] for _ in range(len(self.features))]\n",
    "        for result in array_of_results:\n",
    "            for i, feature in enumerate(self.features):\n",
    "                collated[i].extend(result[feature])\n",
    "        return collated\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"HFCollate(features={self.features})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def clamp(a, x, b):\n",
    "    return min(max(a, x), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "WORK_TYPE_NONE = 0\n",
    "WORK_TYPE_LOAD_BATCHES = 1\n",
    "WORK_TYPE_GET_ITEMS = 2\n",
    "WORK_TYPE_SHUTDOWN = 100\n",
    "\n",
    "class WorkItem:\n",
    "    def __init__(self, type):\n",
    "        self.type = type\n",
    "\n",
    "    def __del__(self):\n",
    "        # print(\"work item dead\", self.type, threading.get_native_id())\n",
    "        pass\n",
    "\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}({str(vars(self))})\"\n",
    "\n",
    "class WorkItemLoadBatches(WorkItem):\n",
    "    def __init__(self, cached_iter: \"Collator.CachedIter\", num_batches):\n",
    "        super().__init__(WORK_TYPE_LOAD_BATCHES)\n",
    "        self.cached_iter = cached_iter\n",
    "        self.num_batches = num_batches\n",
    "\n",
    "    def __del__(self):\n",
    "        # print(\"work item loadbatches dead\", threading.get_native_id())\n",
    "        pass\n",
    "\n",
    "class WorkItemGetItems(WorkItem):\n",
    "    def __init__(self, group: \"WorkGroup\", indices):\n",
    "        super().__init__(WORK_TYPE_GET_ITEMS)\n",
    "        self.group = group\n",
    "        self.indices = indices\n",
    "        self.results = None\n",
    "\n",
    "        self.group.gi_work_array.append(self)\n",
    "\n",
    "    def __del__(self):\n",
    "        # print(\"work item getitems dead\", threading.get_native_id())\n",
    "        pass\n",
    "\n",
    "class COPTS: # CollatorOpts\n",
    "    def __init__(self,\n",
    "                 sampler_iter: mins.SamplerIter = None,\n",
    "                 getitem_func = None,\n",
    "                 collate_func = None,\n",
    "                 *, \n",
    "                 num_threads=None, \n",
    "                 sub_batch_size=None, \n",
    "                 cached_batch_count=1,\n",
    "                 debug_out_queue: queue.SimpleQueue = None):\n",
    "        self.sampler_iter = sampler_iter\n",
    "        self.getitem_func = getitem_func\n",
    "        self.collate_func = collate_func\n",
    "        self.num_threads = num_threads if num_threads is not None else max(1, os.cpu_count()-1)\n",
    "        self.sub_batch_size = sub_batch_size\n",
    "        self.cached_batch_count = cached_batch_count\n",
    "        self.debug_out_queue = debug_out_queue\n",
    "\n",
    "    def finalize(self):\n",
    "        if not self.num_threads:\n",
    "            self.cached_batch_count = 0\n",
    "            self.sub_batch_divisor = 1.0\n",
    "        \n",
    "        self.sub_batch_size = clamp(1, self.sub_batch_size or self.sampler_iter.opts.batch_size, self.sampler_iter.opts.batch_size)\n",
    "\n",
    "        return self\n",
    "\n",
    "class Collator:\n",
    "    class CachedIter:\n",
    "        def __init__(self, serial, iter, num_groups_total):\n",
    "            self.serial = serial\n",
    "            self.iter = iter\n",
    "            self.num_groups_total = num_groups_total\n",
    "            self.num_groups_requested = 0\n",
    "            self.num_groups_started = 0\n",
    "            self.num_groups_finished = 0\n",
    "            self.lock = threading.Lock()\n",
    "            self.collated_queue = queue.SimpleQueue() # Not the greatest to have a queue per CachedIter, but it simplifies the DataLoader\n",
    "\n",
    "        def __del__(self):\n",
    "            # print(\"cached iter dead\", threading.get_native_id())\n",
    "            pass\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"CachedIter(serial={self.serial}, total={self.num_groups_total}, requested={self.num_groups_requested}, started={self.num_groups_started}, finished={self.num_groups_finished})\"\n",
    "\n",
    "    def __init__(self, copts: COPTS):\n",
    "        self.opts = copts.finalize()\n",
    "\n",
    "        self.threads_spawned = False\n",
    "        self.work_queue = queue.SimpleQueue()\n",
    "        self.current_iter_serial = 0\n",
    "        self.shutdown_counter = None\n",
    "\n",
    "    def __del__(self):\n",
    "        # print(\"collator dead\", threading.get_native_id())\n",
    "        pass\n",
    "\n",
    "    def start_new_iter(self):\n",
    "        if not self.threads_spawned: \n",
    "            self.shutdown_counter = threading.Semaphore(self.opts.num_threads)\n",
    "            for i in range(self.opts.num_threads): \n",
    "                threading.Thread(target=collator_threadproc, args=(i+1, self)).start()\n",
    "                self.shutdown_counter.acquire()\n",
    "            \n",
    "            self.threads_spawned = True\n",
    "\n",
    "        self.current_iter_serial += 1\n",
    "        new_iter_serial = self.current_iter_serial\n",
    "        if self.opts.debug_out_queue: self.opts.debug_out_queue.put(f\"[0] New iter {new_iter_serial}\")\n",
    "\n",
    "        cached_iter = self.CachedIter(new_iter_serial, iter(self.opts.sampler_iter), self.opts.sampler_iter.num_batches)\n",
    "        \n",
    "        return cached_iter\n",
    "    \n",
    "    def load_batches(self, cached_iter: CachedIter, num_batches):\n",
    "        queued_any = False\n",
    "\n",
    "        cached_iter.lock.acquire()\n",
    "        new_num_groups_requested = min(cached_iter.num_groups_requested + num_batches, cached_iter.num_groups_total)\n",
    "        if new_num_groups_requested != cached_iter.num_groups_requested:\n",
    "            to_request = new_num_groups_requested-cached_iter.num_groups_requested\n",
    "            self.work_queue.put(WorkItemLoadBatches(cached_iter, to_request))\n",
    "            cached_iter.num_groups_requested = new_num_groups_requested\n",
    "            if self.opts.debug_out_queue: self.opts.debug_out_queue.put(f\"[0] Requesting {to_request} batches for iter {iter_serial}\")\n",
    "            queued_any = True\n",
    "        cached_iter.lock.release()\n",
    "\n",
    "        if self.opts.num_threads == 0 and queued_any:\n",
    "            collator_threadproc(0, self)\n",
    "\n",
    "    def shutdown(self):\n",
    "        if self.threads_spawned:\n",
    "            for _ in range(self.opts.num_threads): self.work_queue.put(WorkItem(WORK_TYPE_SHUTDOWN))\n",
    "            \n",
    "            def wait_for_threads_to_shutdown_and_empty_work_queue(num_threads, shutdown_counter, work_queue):\n",
    "                for _ in range(num_threads): shutdown_counter.acquire()\n",
    "\n",
    "                while not work_queue.empty(): \n",
    "                    got = work_queue.get()\n",
    "                    if type(got) is WorkItemGetItems:\n",
    "                        gi_work: WorkItemGetItems = got\n",
    "                        if gi_work.group:\n",
    "                            assert False # Just want to see if this ever gets hit, theoretically it should\n",
    "                            gi_work.group.complete()\n",
    "            \n",
    "            threading.Thread(target=wait_for_threads_to_shutdown_and_empty_work_queue, \n",
    "                             args=(self.opts.num_threads, self.shutdown_counter, self.work_queue), daemon=True).start()\n",
    "\n",
    "\n",
    "class WorkGroup:\n",
    "    def __init__(self, cached_iter: \"Collator.CachedIter\", batch_serial, num_total):\n",
    "        self.cached_iter = cached_iter\n",
    "        self.batch_serial = batch_serial\n",
    "        self.num_total = num_total\n",
    "        self.gi_work_array: list[WorkItemGetItems] = []\n",
    "\n",
    "        self.num_done_lock = threading.Lock()\n",
    "        self.num_done = 0\n",
    "\n",
    "    def __del__(self):\n",
    "        # print(\"work group dead\", threading.get_native_id())\n",
    "        pass\n",
    "\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}(iter_serial={self.cached_iter.serial}, batch_serial={self.batch_serial}, \"\\\n",
    "                                    f\"num_done={self.num_done}, num_total={self.num_total})\"\n",
    "\n",
    "    def complete(self):\n",
    "        for gi_work in self.gi_work_array: \n",
    "            gi_work.group = None\n",
    "\n",
    "        self.gi_work_array.clear()\n",
    "\n",
    "class CollatedResult:\n",
    "    def __init__(self, batch_serial, result):\n",
    "        self.batch_serial = batch_serial\n",
    "        self.result = result\n",
    "\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}({str(vars(self))})\"\n",
    "\n",
    "\n",
    "def collator_process_one_work(thread_id, work_queue, sub_batch_size, getitem_func, collate_func, shutdown_counter, debug_out_queue):\n",
    "    work: WorkItem = work_queue.get()\n",
    "    if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Got {work}\")\n",
    "    work_type = work.type\n",
    "    \n",
    "    if work_type == WORK_TYPE_LOAD_BATCHES:\n",
    "        lb_work: WorkItemLoadBatches = work\n",
    "        \n",
    "        cached_iter = lb_work.cached_iter\n",
    "        \n",
    "        cached_iter.lock.acquire()\n",
    "        read_num_groups = cached_iter.num_groups_started\n",
    "        \n",
    "        cached_iter.num_groups_started += lb_work.num_batches\n",
    "        array_of_batch_indices = list(itertools.islice(cached_iter.iter, lb_work.num_batches))\n",
    "        cached_iter.lock.release()\n",
    "\n",
    "        batches_spawned = 0\n",
    "        for batch_indices in array_of_batch_indices:\n",
    "            sub_batches = mins.chunkify(batch_indices, sub_batch_size)\n",
    "            assert len(sub_batches)\n",
    "\n",
    "            batch_serial = read_num_groups + batches_spawned\n",
    "            work_group = WorkGroup(lb_work.cached_iter, batch_serial + 1, len(sub_batches))\n",
    "            for sub_batch in sub_batches:\n",
    "                work_queue.put(WorkItemGetItems(work_group, sub_batch))\n",
    "                if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Queued {work_group.gi_work_array[-1]}\")\n",
    "\n",
    "            batches_spawned += 1\n",
    "\n",
    "\n",
    "    elif work_type == WORK_TYPE_GET_ITEMS:\n",
    "        gi_work: WorkItemGetItems = work\n",
    "        work_group = gi_work.group\n",
    "\n",
    "        gi_work.results = getitem_func(gi_work.indices)\n",
    "\n",
    "        work_group.num_done_lock.acquire()\n",
    "        work_group.num_done += 1\n",
    "        work_group.num_done_lock.release()\n",
    "        assert work_group.num_done <= work_group.num_total\n",
    "        \n",
    "        if work_group.num_done == work_group.num_total:\n",
    "            assert work_group.num_done == len(work_group.gi_work_array)\n",
    "            if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Completed group {work_group}\")\n",
    "\n",
    "            cached_iter = work_group.cached_iter\n",
    "            \n",
    "            cached_iter.lock.acquire()\n",
    "            cached_iter.num_groups_finished += 1\n",
    "            is_last_group = cached_iter.num_groups_finished == cached_iter.num_groups_total\n",
    "            cached_iter.lock.release()\n",
    "\n",
    "            collated = collate_func([gi_work.results for gi_work in work_group.gi_work_array])\n",
    "            cached_iter.collated_queue.put(CollatedResult(work_group.batch_serial, collated))\n",
    "\n",
    "            work_group.complete()\n",
    "\n",
    "            if is_last_group:\n",
    "                if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Completed iter {cached_iter.serial}\")\n",
    "                cached_iter.collated_queue.put(CollatedResult(0, None))\n",
    "\n",
    "            if thread_id == 0:\n",
    "                return True\n",
    "\n",
    "\n",
    "    elif work_type == WORK_TYPE_SHUTDOWN:\n",
    "        shutdown_counter.release()\n",
    "        return True\n",
    "\n",
    "    else: assert False\n",
    "\n",
    "    return False\n",
    "\n",
    "def collator_threadproc(thread_id: int, ctx: Collator):\n",
    "    work_queue = ctx.work_queue\n",
    "    sub_batch_size = ctx.opts.sub_batch_size\n",
    "    getitem_func = ctx.opts.getitem_func\n",
    "    collate_func = ctx.opts.collate_func\n",
    "    shutdown_counter = ctx.shutdown_counter\n",
    "    debug_out_queue = ctx.opts.debug_out_queue\n",
    "    \n",
    "    if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Started\")\n",
    "\n",
    "    while 1:\n",
    "        should_exit = collator_process_one_work(thread_id, work_queue, sub_batch_size, getitem_func, collate_func, shutdown_counter, debug_out_queue)\n",
    "        if should_exit:\n",
    "            break\n",
    "\n",
    "    if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Exiting\")\n",
    "\n",
    "\n",
    "class DataLoaderIter:\n",
    "    def __init__(self, collator: Collator, cached_iter: Collator.CachedIter):\n",
    "        self.collator = collator\n",
    "        self.cached_iter = cached_iter\n",
    "        \n",
    "        self.buffer: list[CollatedResult] = []\n",
    "        self.next_batch_index = 1\n",
    "\n",
    "    def __del__(self):\n",
    "        # print(\"dliter dead\", threading.get_native_id())\n",
    "        pass\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"DataLoaderIter({self.cached_iter})\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.collator.load_batches(self.cached_iter, self.collator.opts.cached_batch_count + 1)\n",
    "\n",
    "        while 1:\n",
    "            collated: CollatedResult = self.cached_iter.collated_queue.get()\n",
    "            if not collated.batch_serial:\n",
    "                assert not self.buffer # batch_serial == 0 should strictly come last\n",
    "                break\n",
    "\n",
    "            self.buffer.append(collated)\n",
    "\n",
    "            found_i = next((i for i, x in enumerate(self.buffer) if x.batch_serial == self.next_batch_index), -1)\n",
    "            if found_i != -1:\n",
    "                to_yield = self.buffer[found_i].result\n",
    "                self.buffer[found_i] = self.buffer[-1]\n",
    "                self.buffer.pop()\n",
    "                self.next_batch_index += 1\n",
    "                \n",
    "                yield to_yield\n",
    "                self.collator.load_batches(self.cached_iter, 1)\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, ds, copts: COPTS):\n",
    "        self.ds = ds\n",
    "        self.collator = Collator(copts)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.collator.shutdown()\n",
    "        # print(\"dl dead\", threading.get_native_id())\n",
    "    \n",
    "    def __iter__(self):\n",
    "        cached_iter = self.collator.start_new_iter()\n",
    "        return iter(DataLoaderIter(self.collator, cached_iter))\n",
    "    \n",
    "    @classmethod\n",
    "    def simple(cls, simple_ds: minds.SimpleDataset, sampler_iter_opts: mins.SIO = None, collator_opts: COPTS = None):\n",
    "        sampler_iter_opts = sampler_iter_opts or mins.SIO()\n",
    "        collator_opts = collator_opts or COPTS()\n",
    "\n",
    "        collator_opts.sampler_iter = mins.Sampler(len(simple_ds)).iter(sampler_iter_opts)\n",
    "        collator_opts.getitem_func = simple_ds.__getitem__\n",
    "        collator_opts.collate_func = simple_collate_func\n",
    "        return cls(simple_ds, collator_opts)\n",
    "\n",
    "    @classmethod\n",
    "    def hf(cls, hf_ds: hfds.Dataset, sampler_iter_opts: mins.SIO = None, collator_opts: COPTS = None):\n",
    "        assert type(hf_ds) is hfds.Dataset, f\"Dataset expected, not {type(hf_ds).__name__}\"\n",
    "        sampler_iter_opts = sampler_iter_opts or mins.SIO()\n",
    "        collator_opts = collator_opts or COPTS()\n",
    "\n",
    "        collator_opts.sampler_iter = mins.Sampler(len(hf_ds)).iter(sampler_iter_opts)\n",
    "        collator_opts.getitem_func = hf_ds.__getitem__\n",
    "        collator_opts.collate_func = HFCollate(hf_ds).__call__\n",
    "        return cls(hf_ds, collator_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ([0, 1, 2, 3, 4], [0, -1, -2, -3, -4])\n",
      "2 ([0, 1, 2, 3, 4], [0, -1, -2, -3, -4])\n",
      "1 ([5, 6, 7, 8, 9], [-5, -6, -7, -8, -9])\n",
      "1 ([10, 7, 7, 6, 2], [-10, -7, -7, -6, -2])\n",
      "2 ([5, 6, 7, 8, 9], [-5, -6, -7, -8, -9])\n",
      "2 ([10, 10, 1, 1, 2], [-10, -10, -1, -1, -2])\n",
      "\n",
      "[0, 1, 2, 3, 4] [0, -1, -2, -3, -4]\n",
      "[5, 6, 7, 8, 9] [-5, -6, -7, -8, -9]\n",
      "[10, 7, 8, 1, 7] [-10, -7, -8, -1, -7]\n",
      "agane\n",
      "[0, 1, 2, 3, 4] [0, -1, -2, -3, -4]\n",
      "[5, 6, 7, 8, 9] [-5, -6, -7, -8, -9]\n",
      "[10, 9, 8, 4, 7] [-10, -9, -8, -4, -7]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def getitem_func(indices):\n",
    "    #time.sleep(random.random())\n",
    "    return [[i, -i] for i in indices]\n",
    "\n",
    "dl = DataLoader(None, COPTS(mins.Sampler(11).iter(mins.SIO(5)), getitem_func, simple_collate_func, num_threads=4))\n",
    "\n",
    "it1 = iter(dl)\n",
    "it2 = iter(dl)\n",
    "print(1, next(it1))\n",
    "print(2, next(it2))\n",
    "print(1, next(it1))\n",
    "print(1, next(it1))\n",
    "print(2, next(it2))\n",
    "print(2, next(it2))\n",
    "print()\n",
    "\n",
    "for xb, yb in dl:\n",
    "    print(xb, yb)\n",
    "print(\"agane\")\n",
    "for xb, yb in dl:\n",
    "    print(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SimpleDataset(len=100, xs=int, ys=int),\n",
       " {'opts': <__main__.COPTS at 0x7f26c8a63390>,\n",
       "  'threads_spawned': False,\n",
       "  'work_queue': <_queue.SimpleQueue at 0x7f26c8a877e0>,\n",
       "  'current_iter_serial': 0,\n",
       "  'shutdown_counter': None},\n",
       " {'sampler_iter': <minai.sampler.SamplerIter at 0x7f26c8a63410>,\n",
       "  'getitem_func': <bound method SimpleDataset.__getitem__ of SimpleDataset(len=100, xs=int, ys=int)>,\n",
       "  'collate_func': <function __main__.simple_collate_func(array_of_results)>,\n",
       "  'num_threads': 14,\n",
       "  'sub_batch_size': 16,\n",
       "  'cached_batch_count': 1,\n",
       "  'debug_out_queue': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = minds.SimpleDataset(list(range(100)), list(range(0, -100, -1)))\n",
    "dl = DataLoader.simple(ds, mins.SIO(16))\n",
    "ds, vars(dl.collator), vars(dl.collator.opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15])\n",
      "([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31])\n",
      "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15])\n",
      "([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31])\n"
     ]
    }
   ],
   "source": [
    "it = iter(dl)\n",
    "print(next(it))\n",
    "print(next(it))\n",
    "\n",
    "it = iter(dl)\n",
    "print(next(it))\n",
    "print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 66, 62, 39, 20, 48, 40, 65, 38, 23, 70, 80, 36] [-96, -97, -98, -99, -66, -62, -39, -20, -48, -40, -65, -38, -23, -70, -80, -36]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 2, 6, 89, 41, 60, 58, 91, 48, 85, 43, 48, 16] [-96, -97, -98, -99, -2, -6, -89, -41, -60, -58, -91, -48, -85, -43, -48, -16]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    for xs, ys in dl:\n",
    "        print(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/nblzv/.cache/huggingface/datasets/zh-plus___parquet/Maysee--tiny-imagenet-2eb6c3acd8ebc62a/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fa9d15bf774fb59d724fc3ff7b3e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsd = minds.hf_load(minds.HF_DATASETS.TINY_IMAGENET)\n",
    "dst = dsd[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HFCollate(features=('image', 'label'))\n",
      "[[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7F26C8AC6010>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7F26A01D9C90>, <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7F26A01DAD90>], [0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "c = HFCollate(dst)\n",
    "print(c)\n",
    "print(c([dst[[0, 1]], dst[[2]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64>],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader.hf(dst, mins.SIO(9, False))\n",
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class HFTransform:\n",
    "    def __init__(self, features, transform, **extra_args):\n",
    "        assert type(features) is hfds.features.features.Features\n",
    "        self.features = tuple(features)\n",
    "        self.transform = transform\n",
    "\n",
    "        for k, v in extra_args.items():\n",
    "            super().__setattr__(k ,v)\n",
    "\n",
    "    def __call__(self, results):\n",
    "        return self.transform(self, results)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"HFTransform(features={list(self.features)})\"\n",
    "\n",
    "    @classmethod\n",
    "    def ff_img_to_tensor(cls, features): # first_feature\n",
    "        def tf(ctx: HFTransform, results):\n",
    "            xs = results[ctx.features[0]]\n",
    "            for i in range(len(xs)):\n",
    "                xs[i] = TF.to_tensor(xs[i])\n",
    "            return results\n",
    "        \n",
    "        return cls(features, tf)\n",
    "    \n",
    "    @classmethod\n",
    "    def ff_img_decode_to_tensor(cls, features, half=False): # first_feature\n",
    "        def tf(ctx: HFTransform, results):\n",
    "            xs = results[ctx.features[0]]\n",
    "            for i in range(len(xs)):\n",
    "                raw = torch.frombuffer(xs[i][\"bytes\"], dtype=torch.uint8)\n",
    "                decoded = TFIO.decode_image(raw)\n",
    "                if ctx.half: decoded = decode.half()\n",
    "                else: decoded = decoded.float()\n",
    "                xs[i] = decoded / 255.0\n",
    "            return results\n",
    "        \n",
    "        return cls(features, tf, half=half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def first(iterable):\n",
    "    return next(iter(iterable))\n",
    "\n",
    "def first_value(iterable):\n",
    "    return next(iter(iterable.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_tensor_transform(ctx, results):\n",
    "    xs = results[ctx.features[0]]\n",
    "    for i in range(len(xs)):\n",
    "        xs[i] = TF.to_tensor(xs[i])\n",
    "    return results\n",
    "\n",
    "thds = dst.with_transform(HFTransform(dst.features, to_tensor_transform))\n",
    "dl = DataLoader.hf(thds, mins.SIO(5, False))\n",
    "first(dl)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefetch 0\n",
      "240 ms ± 14.7 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "471 ms ± 42.1 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "735 ms ± 32.6 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "2.3 s ± 122 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "prefetch 1\n",
      "1 s ± 28.7 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "1.49 s ± 482 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "2.22 s ± 266 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtimeit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-r 3 -n 1 bench(1, 2);\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtimeit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-r 3 -n 1 bench(1, 3);\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mtimeit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m-r 3 -n 1 bench(1, 10);\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2419\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.11/site-packages/IPython/core/magics/execution.py:1174\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[39mif\u001b[39;00m time_number \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m:\n\u001b[1;32m   1172\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m all_runs \u001b[39m=\u001b[39m timer\u001b[39m.\u001b[39;49mrepeat(repeat, number)\n\u001b[1;32m   1175\u001b[0m best \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(all_runs) \u001b[39m/\u001b[39m number\n\u001b[1;32m   1176\u001b[0m worst \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(all_runs) \u001b[39m/\u001b[39m number\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.11/timeit.py:206\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    204\u001b[0m r \u001b[39m=\u001b[39m []\n\u001b[1;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(repeat):\n\u001b[0;32m--> 206\u001b[0m     t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeit(number)\n\u001b[1;32m    207\u001b[0m     r\u001b[39m.\u001b[39mappend(t)\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.11/site-packages/IPython/core/magics/execution.py:158\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    156\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[1;32m    159\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mbench\u001b[0;34m(cached_batch_count, next_count)\u001b[0m\n\u001b[1;32m      3\u001b[0m dl \u001b[39m=\u001b[39m DataLoader\u001b[39m.\u001b[39mhf(tdst, mins\u001b[39m.\u001b[39mSIO(\u001b[39m1024\u001b[39m), collator_opts\u001b[39m=\u001b[39mCOPTS(cached_batch_count\u001b[39m=\u001b[39mcached_batch_count, sub_batch_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m))\n\u001b[1;32m      4\u001b[0m it \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(dl)\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(next_count): \u001b[39mnext\u001b[39m(it)\n",
      "Cell \u001b[0;32mIn[4], line 292\u001b[0m, in \u001b[0;36mDataLoaderIter.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollator\u001b[39m.\u001b[39mload_batches(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_iter, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollator\u001b[39m.\u001b[39mopts\u001b[39m.\u001b[39mcached_batch_count \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 292\u001b[0m     collated: CollatedResult \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcached_iter\u001b[39m.\u001b[39;49mcollated_queue\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m    293\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m collated\u001b[39m.\u001b[39mbatch_serial:\n\u001b[1;32m    294\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m# batch_serial == 0 should strictly come last\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tdst = dst.with_transform(HFTransform.ff_img_to_tensor(dst.features))\n",
    "def bench(cached_batch_count, next_count):\n",
    "    dl = DataLoader.hf(tdst, mins.SIO(1024), collator_opts=COPTS(cached_batch_count=cached_batch_count, sub_batch_size=512))\n",
    "    it = iter(dl)\n",
    "    for _ in range(next_count): next(it)\n",
    "\n",
    "print(\"prefetch 0\")\n",
    "%timeit -r 3 -n 1 bench(0, 1);\n",
    "%timeit -r 3 -n 1 bench(0, 2);\n",
    "%timeit -r 3 -n 1 bench(0, 3);\n",
    "%timeit -r 3 -n 1 bench(0, 10);\n",
    "print(\"prefetch 1\")\n",
    "%timeit -r 3 -n 1 bench(1, 1); # For some reason this shows as slower when it is in fact pretty much the same time for the first batch to complete\n",
    "%timeit -r 3 -n 1 bench(1, 2);\n",
    "%timeit -r 3 -n 1 bench(1, 3);\n",
    "%timeit -r 3 -n 1 bench(1, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefetch 0\n",
      "94.7 ms ± 12.3 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "185 ms ± 5.67 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "287 ms ± 25.5 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "913 ms ± 13 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "prefetch 1\n",
      "416 ms ± 27 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "792 ms ± 242 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "913 ms ± 153 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "1.62 s ± 336 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "tdst = dst.with_transform(HFTransform.ff_img_decode_to_tensor(dst.features)).cast_column(\"image\", hfds.Image(decode=False))\n",
    "def bench(cached_batch_count, next_count):\n",
    "    dl = DataLoader.hf(tdst, mins.SIO(1024), collator_opts=COPTS(cached_batch_count=cached_batch_count, sub_batch_size=512))\n",
    "    it = iter(dl)\n",
    "    for _ in range(next_count): next(it)\n",
    "    \n",
    "print(\"prefetch 0\")\n",
    "%timeit -r 3 -n 1 bench(0, 1);\n",
    "%timeit -r 3 -n 1 bench(0, 2);\n",
    "%timeit -r 3 -n 1 bench(0, 3);\n",
    "%timeit -r 3 -n 1 bench(0, 10);\n",
    "print(\"prefetch 1\")\n",
    "%timeit -r 3 -n 1 bench(1, 1); # For some reason this shows as slower when it is in fact pretty much the same time for the first batch to complete\n",
    "%timeit -r 3 -n 1 bench(1, 2);\n",
    "%timeit -r 3 -n 1 bench(1, 3);\n",
    "%timeit -r 3 -n 1 bench(1, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class DataLoaderDict(dict):\n",
    "    def __init__(self, dataloaders_dict: dict[str, DataLoader]):\n",
    "        super().__init__(dataloaders_dict)\n",
    "\n",
    "    def __getitem__(self, key) -> DataLoader:\n",
    "        return super().__getitem__(key)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"DataLoaders({super().__repr__()})\"\n",
    "\n",
    "    @classmethod\n",
    "    def hf(cls, dsd: hfds.DatasetDict, sampler_iter_opts: mins.SIO = None, collator_opts: COPTS = None):\n",
    "        dls = {k: DataLoader.hf(dsd[k], sampler_iter_opts, collator_opts) for k in dsd}\n",
    "        return cls(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoaders({'train': <__main__.DataLoader object at 0x7f2002af7bd0>, 'valid': <__main__.DataLoader object at 0x7f2002af5f50>})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaderDict.hf(dsd)\n",
    "dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing minai_nbs/datasets.ipynb -> minai/minai/datasets.py  |  same contents, skipping, took 0.001s\n",
      "Processing minai_nbs/sampler.ipynb -> minai/minai/sampler.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/setup+template.py -> minai/setup.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/__init__+template.py -> minai/minai/__init__.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/plot.ipynb -> minai/minai/plot.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/mintils.py -> minai/minai/mintils.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/data.ipynb -> minai/minai/data.py  |  7 cells exported, took 0.000s \n",
      "\n",
      "All done... took 0.002s\n",
      "  lib_name: minai\n",
      "  author: nblzv\n",
      "  version: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "import z_export\n",
    "z_export.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
