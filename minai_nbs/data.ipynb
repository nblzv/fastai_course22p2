{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "import threading\n",
    "import queue\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import datasets as hfds\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.io as TFIO\n",
    "\n",
    "import minai.sampler as mins\n",
    "import minai.datasets as minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def simple_collate_func(array_of_results):\n",
    "    xs = [r[0] for results in array_of_results for r in results]\n",
    "    ys = [r[1] for results in array_of_results for r in results]\n",
    "    return xs, ys\n",
    "\n",
    "class HFCollate:\n",
    "    def __init__(self, ds: hfds.Dataset, device=None):\n",
    "        self.features = tuple(ds.features.keys())\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, array_of_results):\n",
    "        collated = [[] for _ in range(len(self.features))]\n",
    "        for result in array_of_results:\n",
    "            for i, feature in enumerate(self.features):\n",
    "                collated[i].extend(result[feature])\n",
    "\n",
    "        for i in range(len(collated)):\n",
    "            if type(collated[i][0]) is not torch.Tensor:\n",
    "                collated[i] = torch.tensor(collated[i]).to(self.device)\n",
    "            else:\n",
    "                collated[i] = torch.stack(collated[i]).to(self.device)\n",
    "\n",
    "        return collated\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"HFCollate(features={self.features}, device={self.device})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def clamp(a, x, b):\n",
    "    return min(max(a, x), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "WORK_TYPE_NONE = 0\n",
    "WORK_TYPE_LOAD_BATCHES = 1\n",
    "WORK_TYPE_GET_ITEMS = 2\n",
    "WORK_TYPE_SHUTDOWN = 100\n",
    "\n",
    "class WorkItem:\n",
    "    def __init__(self, type):\n",
    "        self.type = type\n",
    "\n",
    "    #def __del__(self): print(\"work item dead\", self.type, threading.get_native_id())\n",
    "\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}({str(vars(self))})\"\n",
    "\n",
    "class WorkItemLoadBatches(WorkItem):\n",
    "    def __init__(self, cached_iter: \"Collator.CachedIter\", num_batches):\n",
    "        super().__init__(WORK_TYPE_LOAD_BATCHES)\n",
    "        self.cached_iter = cached_iter\n",
    "        self.num_batches = num_batches\n",
    "\n",
    "    #def __del__(self): print(\"work item loadbatches dead\", threading.get_native_id())\n",
    "\n",
    "class WorkItemGetItems(WorkItem):\n",
    "    def __init__(self, group: \"WorkGroup\", indices):\n",
    "        super().__init__(WORK_TYPE_GET_ITEMS)\n",
    "        self.group = group\n",
    "        self.indices = indices\n",
    "        self.results = None\n",
    "\n",
    "        self.group.gi_work_array.append(self)\n",
    "\n",
    "    #def __del__(self): print(\"work item getitems dead\", threading.get_native_id())\n",
    "\n",
    "class COPTS: # CollatorOpts\n",
    "    def __init__(self,\n",
    "                 *, \n",
    "                 num_threads = None, \n",
    "                 debug_out_queue: queue.SimpleQueue = None):\n",
    "        self.num_threads = num_threads\n",
    "        self.debug_out_queue = debug_out_queue\n",
    "    \n",
    "    def __repr__(self): return str(vars(self))\n",
    "\n",
    "    def finalize(self):\n",
    "        cpu_count = os.cpu_count()\n",
    "        if self.num_threads is None: self.num_threads = max(1, cpu_count//2)\n",
    "        self.num_threads = clamp(0, self.num_threads, cpu_count*10)\n",
    "\n",
    "        return self\n",
    "\n",
    "class COIOPTS: # Collator(Cached)IterOpts\n",
    "    DEFAULT_DEVICE = None\n",
    "\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 sampler_iter: mins.SamplerIter = None,\n",
    "                 cached_batch_count = 1,\n",
    "                 sub_batch_size = None,\n",
    "                 getitem_func = None,\n",
    "                 collate_func = None,\n",
    "                 collate_device = None):\n",
    "\n",
    "        self.sampler_iter = sampler_iter\n",
    "        self.cached_batch_count = cached_batch_count\n",
    "        self.sub_batch_size = sub_batch_size\n",
    "        self.getitem_func = getitem_func\n",
    "        self.collate_func = collate_func\n",
    "        self.collate_device = collate_device or self.DEFAULT_DEVICE\n",
    "\n",
    "    def __repr__(self): return str(vars(self))\n",
    "\n",
    "    def finalize(self, collator_opts: COPTS):\n",
    "        if collator_opts.num_threads == 0:\n",
    "            self.cached_batch_count = 0\n",
    "            self.sub_batch_size = self.sampler_iter.opts.batch_size\n",
    "        else:\n",
    "            if self.sub_batch_size is None:\n",
    "                self.sub_batch_size = math.ceil(self.sampler_iter.opts.batch_size / collator_opts.num_threads)\n",
    "            elif self.sub_batch_size == 0:\n",
    "                self.sub_batch_size = self.sampler_iter.opts.batch_size\n",
    "\n",
    "        self.sub_batch_size = clamp(1, self.sub_batch_size, self.sampler_iter.opts.batch_size)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "class Collator:\n",
    "    class CachedIter:\n",
    "        def __init__(self, serial, collator_iter_opts: COIOPTS):\n",
    "            self.serial = serial\n",
    "            self.opts = collator_iter_opts\n",
    "            self.iter = iter(collator_iter_opts.sampler_iter)\n",
    "            self.num_groups_total = collator_iter_opts.sampler_iter.num_batches\n",
    "            self.num_groups_requested = 0\n",
    "            self.num_groups_started = 0\n",
    "            self.num_groups_finished = 0\n",
    "            self.lock = threading.Lock()\n",
    "            self.collated_queue = queue.SimpleQueue()\n",
    "\n",
    "        #def __del__(self): print(\"cached iter dead\", threading.get_native_id())\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"CachedIter(serial={self.serial}, total={self.num_groups_total}, requested={self.num_groups_requested}, started={self.num_groups_started}, finished={self.num_groups_finished}, opts={self.opts})\"\n",
    "\n",
    "    def __init__(self, copts: COPTS):\n",
    "        self.opts = copts.finalize()\n",
    "\n",
    "        self.threads_spawned = False\n",
    "        self.work_queue = queue.SimpleQueue()\n",
    "        self.current_iter_serial = 0\n",
    "        self.shutdown_counter = None\n",
    "        self.registered_dl_count = 0\n",
    "\n",
    "    #def __del__(self): print(\"collator dead\", threading.get_native_id())\n",
    "\n",
    "    def __repr__(self): return str(vars(self))\n",
    "\n",
    "    def start_new_iter(self, collator_iter_opts: COIOPTS):\n",
    "        if not self.threads_spawned: \n",
    "            self.shutdown_counter = threading.Semaphore(self.opts.num_threads)\n",
    "            for i in range(self.opts.num_threads): \n",
    "                threading.Thread(target=collator_threadproc, args=(i+1, self)).start()\n",
    "                self.shutdown_counter.acquire()\n",
    "            \n",
    "            self.threads_spawned = True\n",
    "\n",
    "        self.current_iter_serial += 1\n",
    "        new_iter_serial = self.current_iter_serial\n",
    "        if self.opts.debug_out_queue: self.opts.debug_out_queue.put(f\"[0] New iter {new_iter_serial}\")\n",
    "\n",
    "        cached_iter = self.CachedIter(new_iter_serial, collator_iter_opts)\n",
    "        \n",
    "        return cached_iter\n",
    "    \n",
    "    def load_batches(self, cached_iter: CachedIter, num_batches):\n",
    "        if not num_batches: return\n",
    "        \n",
    "        cached_iter.lock.acquire()\n",
    "        to_request = min(num_batches, cached_iter.num_groups_total - cached_iter.num_groups_requested)\n",
    "        cached_iter.num_groups_requested += to_request\n",
    "        cached_iter.lock.release()\n",
    "\n",
    "        if to_request:\n",
    "            self.work_queue.put(WorkItemLoadBatches(cached_iter, to_request))\n",
    "            if self.opts.debug_out_queue: self.opts.debug_out_queue.put(f\"[0] Requesting {to_request} batches for iter {cached_iter.serial}\")\n",
    "\n",
    "            if self.opts.num_threads == 0:\n",
    "                collator_threadproc(0, self)\n",
    "\n",
    "    def register_dl(self): \n",
    "        self.registered_dl_count += 1\n",
    "    def unregister_dl(self): \n",
    "        self.registered_dl_count -= 1\n",
    "        if self.registered_dl_count == 0:\n",
    "            self.shutdown()\n",
    "\n",
    "    def shutdown(self):\n",
    "        if self.threads_spawned:\n",
    "            for _ in range(self.opts.num_threads): self.work_queue.put(WorkItem(WORK_TYPE_SHUTDOWN))\n",
    "            \n",
    "            def wait_for_threads_to_shutdown_and_empty_work_queue(num_threads, shutdown_counter, work_queue):\n",
    "                for _ in range(num_threads): shutdown_counter.acquire()\n",
    "\n",
    "                while not work_queue.empty(): \n",
    "                    got = work_queue.get()\n",
    "                    if type(got) is WorkItemGetItems:\n",
    "                        gi_work: WorkItemGetItems = got\n",
    "                        if gi_work.group: gi_work.group.complete()\n",
    "            \n",
    "            threading.Thread(target=wait_for_threads_to_shutdown_and_empty_work_queue, \n",
    "                             args=(self.opts.num_threads, self.shutdown_counter, self.work_queue), daemon=True).start()\n",
    "\n",
    "\n",
    "class WorkGroup:\n",
    "    def __init__(self, cached_iter: \"Collator.CachedIter\", batch_serial, num_total):\n",
    "        self.cached_iter = cached_iter\n",
    "        self.batch_serial = batch_serial\n",
    "        self.num_total = num_total\n",
    "        self.gi_work_array: list[WorkItemGetItems] = []\n",
    "\n",
    "        self.num_done_lock = threading.Lock()\n",
    "        self.num_done = 0\n",
    "\n",
    "    #def __del__(self): print(\"work group dead\", threading.get_native_id())\n",
    "\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}(iter_serial={self.cached_iter.serial}, batch_serial={self.batch_serial}, \"\\\n",
    "                                    f\"num_done={self.num_done}, num_total={self.num_total})\"\n",
    "\n",
    "    def complete(self):\n",
    "        for gi_work in self.gi_work_array: \n",
    "            gi_work.group = None\n",
    "\n",
    "        self.gi_work_array.clear()\n",
    "\n",
    "class CollatedResult:\n",
    "    def __init__(self, batch_serial, result):\n",
    "        self.batch_serial = batch_serial\n",
    "        self.result = result\n",
    "\n",
    "    #def __del__(self): print(\"collatedresult dead\")\n",
    "\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}({str(vars(self))})\"\n",
    "\n",
    "\n",
    "def collator_process_one_work(thread_id, work_queue, shutdown_counter, debug_out_queue):\n",
    "    work: WorkItem = work_queue.get()\n",
    "\n",
    "    if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Got {work}\")\n",
    "    work_type = work.type\n",
    "    \n",
    "    if work_type == WORK_TYPE_LOAD_BATCHES:\n",
    "        lb_work: WorkItemLoadBatches = work\n",
    "        \n",
    "        cached_iter = lb_work.cached_iter\n",
    "        \n",
    "        cached_iter.lock.acquire()\n",
    "        read_num_groups = cached_iter.num_groups_started\n",
    "        \n",
    "        cached_iter.num_groups_started += lb_work.num_batches\n",
    "        array_of_batch_indices = list(itertools.islice(cached_iter.iter, lb_work.num_batches))\n",
    "        cached_iter.lock.release()\n",
    "\n",
    "        batches_spawned = 0\n",
    "        for batch_indices in array_of_batch_indices:\n",
    "            sub_batches = mins.chunkify(batch_indices, cached_iter.opts.sub_batch_size)\n",
    "            assert len(sub_batches)\n",
    "\n",
    "            batch_serial = read_num_groups + batches_spawned\n",
    "            work_group = WorkGroup(cached_iter, batch_serial + 1, len(sub_batches))\n",
    "            for sub_batch in sub_batches:\n",
    "                work_queue.put(WorkItemGetItems(work_group, sub_batch))\n",
    "                if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Queued {work_group.gi_work_array[-1]}\")\n",
    "\n",
    "            batches_spawned += 1\n",
    "\n",
    "\n",
    "    elif work_type == WORK_TYPE_GET_ITEMS:\n",
    "        gi_work: WorkItemGetItems = work\n",
    "        work_group = gi_work.group\n",
    "        cached_iter = work_group.cached_iter\n",
    "\n",
    "        gi_work.results = cached_iter.opts.getitem_func(gi_work.indices)\n",
    "\n",
    "        work_group.num_done_lock.acquire()\n",
    "        work_group.num_done += 1\n",
    "        work_group.num_done_lock.release()\n",
    "        assert work_group.num_done <= work_group.num_total\n",
    "        \n",
    "        if work_group.num_done == work_group.num_total:\n",
    "            assert work_group.num_done == len(work_group.gi_work_array)\n",
    "            if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Completed group {work_group}\")\n",
    "\n",
    "            \n",
    "            cached_iter.lock.acquire()\n",
    "            cached_iter.num_groups_finished += 1\n",
    "            is_last_group = cached_iter.num_groups_finished == cached_iter.num_groups_total\n",
    "            cached_iter.lock.release()\n",
    "\n",
    "            collated = cached_iter.opts.collate_func([gi_work.results for gi_work in work_group.gi_work_array])\n",
    "            cached_iter.collated_queue.put(CollatedResult(work_group.batch_serial, collated))\n",
    "\n",
    "            if is_last_group:\n",
    "                if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Completed iter {cached_iter.serial}\")\n",
    "                cached_iter.collated_queue.put(CollatedResult(0, None))\n",
    "\n",
    "            work_group.complete()\n",
    "\n",
    "            if thread_id == 0:\n",
    "                return True\n",
    "\n",
    "\n",
    "    elif work_type == WORK_TYPE_SHUTDOWN:\n",
    "        shutdown_counter.release()\n",
    "        return True\n",
    "\n",
    "    else: assert False\n",
    "\n",
    "    return False\n",
    "\n",
    "def collator_threadproc(thread_id: int, ctx: Collator):\n",
    "    work_queue = ctx.work_queue\n",
    "    shutdown_counter = ctx.shutdown_counter\n",
    "    debug_out_queue = ctx.opts.debug_out_queue\n",
    "    \n",
    "    if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Started\")\n",
    "\n",
    "    while 1:\n",
    "        should_exit = collator_process_one_work(thread_id, work_queue, shutdown_counter, debug_out_queue)\n",
    "        if should_exit:\n",
    "            break\n",
    "\n",
    "    if debug_out_queue: debug_out_queue.put(f\"[{thread_id}] Exiting\")\n",
    "\n",
    "\n",
    "class DataLoaderIter:\n",
    "    def __init__(self, collator: Collator, cached_iter: Collator.CachedIter):\n",
    "        self.collator = collator\n",
    "        self.cached_iter = cached_iter\n",
    "        \n",
    "        self.buffer: list[CollatedResult] = []\n",
    "        self.next_batch_index = 1\n",
    "\n",
    "    #def __del__(self): print(\"dliter dead\", threading.get_native_id())\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"DataLoaderIter({self.cached_iter})\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.collator.load_batches(self.cached_iter, self.cached_iter.opts.cached_batch_count + 1)\n",
    "\n",
    "        while 1:\n",
    "            collated: CollatedResult = self.cached_iter.collated_queue.get()\n",
    "            if not collated.batch_serial:\n",
    "                assert not self.buffer # batch_serial == 0 should strictly come last\n",
    "                break\n",
    "\n",
    "            self.buffer.append(collated)\n",
    "\n",
    "            while 1:\n",
    "                found_i = next((i for i, x in enumerate(self.buffer) if x.batch_serial == self.next_batch_index), -1)\n",
    "                if found_i == -1:\n",
    "                    break\n",
    "\n",
    "                to_yield = self.buffer[found_i].result\n",
    "                self.buffer[found_i] = self.buffer[-1]\n",
    "                self.buffer.pop()\n",
    "                self.next_batch_index += 1\n",
    "                \n",
    "                yield to_yield\n",
    "                self.collator.load_batches(self.cached_iter, 1)\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, ds, collator: Collator, collator_iter_opts: COIOPTS):\n",
    "        self.ds = ds\n",
    "        self.collator = collator\n",
    "        self.opts = collator_iter_opts\n",
    "        \n",
    "        self.opts.finalize(self.collator.opts)\n",
    "        self.collator.register_dl()\n",
    "\n",
    "    def __del__(self): \n",
    "        #print(\"dl dead\", threading.get_native_id())\n",
    "        self.collator.unregister_dl()\n",
    "    \n",
    "    def __repr__(self): return str(vars(self))\n",
    "\n",
    "    def __iter__(self):\n",
    "        cached_iter = self.collator.start_new_iter(self.opts)\n",
    "        return iter(DataLoaderIter(self.collator, cached_iter))\n",
    "    \n",
    "    @classmethod\n",
    "    def solo(cls, ds, collator_opts: COPTS, collator_iter_opts: COIOPTS):\n",
    "        collator = Collator(collator_opts)\n",
    "        return cls(ds, collator, collator_iter_opts)\n",
    "\n",
    "    @classmethod\n",
    "    def simple(cls, simple_ds: minds.SimpleDataset, sampler_iter_opts: mins.SIO = None, collator_opts: COPTS = None, collator_iter_opts: COIOPTS = None):\n",
    "        sampler_iter_opts = sampler_iter_opts or mins.SIO()\n",
    "        collator_opts = collator_opts or COPTS()\n",
    "        collator_iter_opts = collator_iter_opts or COIOPTS()\n",
    "\n",
    "        collator_iter_opts.sampler_iter = mins.Sampler(len(simple_ds)).iter(sampler_iter_opts)\n",
    "        collator_iter_opts.getitem_func = simple_ds.__getitem__\n",
    "        collator_iter_opts.collate_func = simple_collate_func\n",
    "        return cls.solo(simple_ds, collator_opts, collator_iter_opts)\n",
    "\n",
    "    @classmethod\n",
    "    def hf(cls, hf_ds: hfds.Dataset, sampler_iter_opts: mins.SIO = None, collator_opts: COPTS = None, collator_iter_opts: COIOPTS = None):\n",
    "        assert type(hf_ds) is hfds.Dataset, f\"Dataset expected, not {type(hf_ds).__name__}\"\n",
    "        sampler_iter_opts = sampler_iter_opts or mins.SIO()\n",
    "        collator_opts = collator_opts or COPTS()\n",
    "        collator_iter_opts = collator_iter_opts or COIOPTS()\n",
    "        \n",
    "        collator_iter_opts.sampler_iter = mins.Sampler(len(hf_ds)).iter(sampler_iter_opts)\n",
    "        collator_iter_opts.getitem_func = hf_ds.__getitem__\n",
    "        collator_iter_opts.collate_func = HFCollate(hf_ds, collator_iter_opts.collate_device).__call__\n",
    "        return cls.solo(hf_ds, collator_opts, collator_iter_opts)\n",
    "    \n",
    "    @classmethod\n",
    "    def hf_dsd(cls, hf_ds: hfds.Dataset, collator: Collator, sampler_iter_opts: mins.SIO = None, collator_iter_opts: COIOPTS = None):\n",
    "        assert type(hf_ds) is hfds.Dataset, f\"Dataset expected, not {type(hf_ds).__name__}\"\n",
    "        sampler_iter_opts = sampler_iter_opts or mins.SIO()\n",
    "        collator_iter_opts = collator_iter_opts or COIOPTS()\n",
    "        \n",
    "        collator_iter_opts.sampler_iter = mins.Sampler(len(hf_ds)).iter(sampler_iter_opts)\n",
    "        collator_iter_opts.getitem_func = hf_ds.__getitem__\n",
    "        collator_iter_opts.collate_func = HFCollate(hf_ds, collator_iter_opts.collate_device).__call__\n",
    "        return cls(hf_ds, collator, collator_iter_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ([0, 1, 2, 3, 4], [0, -1, -2, -3, -4])\n",
      "2 ([0, 1, 2, 3, 4], [0, -1, -2, -3, -4])\n",
      "1 ([5, 6, 7, 8, 9], [-5, -6, -7, -8, -9])\n",
      "1 ([10, 4, 9, 1, 2], [-10, -4, -9, -1, -2])\n",
      "2 ([5, 6, 7, 8, 9], [-5, -6, -7, -8, -9])\n",
      "2 ([10, 0, 3, 9, 4], [-10, 0, -3, -9, -4])\n",
      "\n",
      "[0, 1, 2, 3, 4] [0, -1, -2, -3, -4]\n",
      "[5, 6, 7, 8, 9] [-5, -6, -7, -8, -9]\n",
      "[10, 6, 4, 5, 4] [-10, -6, -4, -5, -4]\n",
      "agane\n",
      "[0, 1, 2, 3, 4] [0, -1, -2, -3, -4]\n",
      "[5, 6, 7, 8, 9] [-5, -6, -7, -8, -9]\n",
      "[10, 1, 7, 6, 8] [-10, -1, -7, -6, -8]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def getitem_func(indices):\n",
    "    #time.sleep(random.random())\n",
    "    return [[i, -i] for i in indices]\n",
    "\n",
    "dl = DataLoader.solo(None, \n",
    "                     COPTS(num_threads=4),\n",
    "                     COIOPTS(sampler_iter=mins.Sampler(11).iter(mins.SIO(5)), \n",
    "                             getitem_func=getitem_func, \n",
    "                             collate_func=simple_collate_func))\n",
    "\n",
    "it1 = iter(dl)\n",
    "it2 = iter(dl)\n",
    "print(1, next(it1))\n",
    "print(2, next(it2))\n",
    "print(1, next(it1))\n",
    "print(1, next(it1))\n",
    "print(2, next(it2))\n",
    "print(2, next(it2))\n",
    "print()\n",
    "\n",
    "for xb, yb in dl:\n",
    "    print(xb, yb)\n",
    "print(\"agane\")\n",
    "for xb, yb in dl:\n",
    "    print(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def foo():\n",
    "    dl = DataLoader.solo(None, \n",
    "                     COPTS(num_threads=4),\n",
    "                     COIOPTS(sampler_iter=mins.Sampler(11).iter(mins.SIO(5)), \n",
    "                             getitem_func=getitem_func, \n",
    "                             collate_func=simple_collate_func))\n",
    "    next(iter(dl))\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SimpleDataset(len=100, xs=int, ys=int),\n",
       " {'opts': {'num_threads': 7, 'debug_out_queue': None},\n",
       "  'threads_spawned': False,\n",
       "  'work_queue': <_queue.SimpleQueue at 0x7f808ecac270>,\n",
       "  'current_iter_serial': 0,\n",
       "  'shutdown_counter': None,\n",
       "  'registered_dl_count': 1},\n",
       " {'num_threads': 7, 'debug_out_queue': None})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = minds.SimpleDataset(list(range(100)), list(range(0, -100, -1)))\n",
    "dl = DataLoader.simple(ds, mins.SIO(16))\n",
    "ds, vars(dl.collator), vars(dl.collator.opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15])\n",
      "([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31])\n",
      "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15])\n",
      "([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31])\n"
     ]
    }
   ],
   "source": [
    "it = iter(dl)\n",
    "print(next(it))\n",
    "print(next(it))\n",
    "\n",
    "it = iter(dl)\n",
    "print(next(it))\n",
    "print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 18, 31, 26, 13, 34, 21, 96, 45, 35, 2, 59, 4] [-96, -97, -98, -99, -18, -31, -26, -13, -34, -21, -96, -45, -35, -2, -59, -4]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 16, 72, 93, 26, 35, 26, 81, 36, 50, 53, 55, 83] [-96, -97, -98, -99, -16, -72, -93, -26, -35, -26, -81, -36, -50, -53, -55, -83]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    for xs, ys in dl:\n",
    "        print(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/nblzv/.cache/huggingface/datasets/zh-plus___parquet/Maysee--tiny-imagenet-2eb6c3acd8ebc62a/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0151d4589c24d0184281350e5f0e582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsd = minds.hf_load(minds.HF_DATASETS.TINY_IMAGENET)\n",
    "dst = dsd[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class HFTransform:\n",
    "    def __init__(self, features, transform, **extra_args):\n",
    "        assert type(features) is hfds.features.features.Features\n",
    "        self.features = tuple(features)\n",
    "        self.transform = transform\n",
    "\n",
    "        for k, v in extra_args.items():\n",
    "            super().__setattr__(k ,v)\n",
    "\n",
    "    def __call__(self, results):\n",
    "        return self.transform(self, results)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"HFTransform(features={list(self.features)})\"\n",
    "\n",
    "    @classmethod\n",
    "    def ff_img_to_tensor(cls, features, n_channels=3): # first_feature\n",
    "        def tf(ctx: HFTransform, results):\n",
    "            xs = results[ctx.features[0]]\n",
    "            for i in range(len(xs)):\n",
    "                decoded = TF.to_tensor(xs[i])\n",
    "                xs[i] = decoded.expand(ctx.n_channels, *decoded.shape[1:])\n",
    "            return results\n",
    "        \n",
    "        return cls(features, tf, n_channels=n_channels)\n",
    "    \n",
    "    @classmethod\n",
    "    def ff_img_decode_to_tensor(cls, features, n_channels=3, half=False): # first_feature\n",
    "        def tf(ctx: HFTransform, results):\n",
    "            xs = results[ctx.features[0]]\n",
    "            for i in range(len(xs)):\n",
    "                raw = torch.frombuffer(xs[i][\"bytes\"], dtype=torch.uint8)\n",
    "                decoded = TFIO.decode_image(raw)\n",
    "                decoded = decoded.expand(ctx.n_channels, *decoded.shape[1:])\n",
    "                if ctx.half: decoded = decoded.half()\n",
    "                else: decoded = decoded.float()\n",
    "                xs[i] = decoded / 255.0\n",
    "            return results\n",
    "        \n",
    "        return cls(features, tf, n_channels=n_channels, half=half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def first(iterable):\n",
    "    return next(iter(iterable))\n",
    "\n",
    "def first_value(iterable):\n",
    "    return next(iter(iterable.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_tensor_transform(ctx, results):\n",
    "    xs = results[ctx.features[0]]\n",
    "    for i in range(len(xs)):\n",
    "        xs[i] = TF.to_tensor(xs[i])\n",
    "    return results\n",
    "\n",
    "thds = dst.with_transform(HFTransform(dst.features, to_tensor_transform))\n",
    "dl = DataLoader.hf(thds, mins.SIO(5, False))\n",
    "first(dl)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefetch 0\n",
      "308 ms ± 5.38 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "852 ms ± 14.9 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "prefetch 1\n",
      "1.38 s ± 117 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "2.79 s ± 122 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "tdst = dst.with_transform(HFTransform.ff_img_to_tensor(dst.features))\n",
    "def bench(cached_batch_count, next_count):\n",
    "    dl = DataLoader.hf(tdst, \n",
    "                       mins.SIO(1024), \n",
    "                       collator_opts=COPTS(),\n",
    "                       collator_iter_opts=COIOPTS(cached_batch_count=cached_batch_count, sub_batch_size=512))\n",
    "    it = iter(dl)\n",
    "    for _ in range(next_count): next(it)\n",
    "\n",
    "print(\"prefetch 0\")\n",
    "%timeit -r 3 -n 1 bench(0, 1);\n",
    "%timeit -r 3 -n 1 bench(0, 3);\n",
    "print(\"prefetch 1\")\n",
    "%timeit -r 3 -n 1 bench(1, 1);\n",
    "%timeit -r 3 -n 1 bench(1, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefetch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19341/4268657344.py:33: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1687158866840/work/torch/csrc/utils/tensor_new.cpp:1505.)\n",
      "  raw = torch.frombuffer(xs[i][\"bytes\"], dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 ms ± 13.6 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "339 ms ± 31 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "prefetch 1\n",
      "645 ms ± 40.4 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "1.35 s ± 30.5 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "tdst = dst.with_transform(HFTransform.ff_img_decode_to_tensor(dst.features)).cast_column(\"image\", hfds.Image(decode=False))\n",
    "def bench(cached_batch_count, next_count):\n",
    "    dl = DataLoader.hf(tdst, mins.SIO(1024), \n",
    "                       collator_opts=COPTS(),\n",
    "                       collator_iter_opts=COIOPTS(cached_batch_count=cached_batch_count, sub_batch_size=512))\n",
    "    it = iter(dl)\n",
    "    for _ in range(next_count): next(it)\n",
    "\n",
    "print(\"prefetch 0\")\n",
    "%timeit -r 3 -n 1 bench(0, 1);\n",
    "%timeit -r 3 -n 1 bench(0, 3);\n",
    "print(\"prefetch 1\")\n",
    "%timeit -r 3 -n 1 bench(1, 1);\n",
    "%timeit -r 3 -n 1 bench(1, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class DataLoaderDict(dict):\n",
    "    def __init__(self, collator: Collator, dataloaders_dict: dict[str, DataLoader]):\n",
    "        self.collator = collator\n",
    "        super().__init__(dataloaders_dict)\n",
    "\n",
    "    def __getitem__(self, key) -> DataLoader:\n",
    "        return super().__getitem__(key)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"DataLoaders({list(self.keys())})\"\n",
    "\n",
    "    @classmethod\n",
    "    def hf(cls, dsd: hfds.DatasetDict, \n",
    "           collator_opts: COPTS = None, \n",
    "           sampler_iter_opts: dict[str, mins.SIO] = {}, \n",
    "           collator_iter_opts: dict[str, COIOPTS] = {}):\n",
    "        \n",
    "        collator_opts = collator_opts or COPTS()\n",
    "        collator = Collator(collator_opts)\n",
    "\n",
    "        if type(sampler_iter_opts) is mins.SIO:\n",
    "            sio_default = sampler_iter_opts\n",
    "            sampler_iter_opts = {}\n",
    "        else:\n",
    "            sio_default = mins.SIO()\n",
    "\n",
    "        if type(collator_iter_opts) is COIOPTS:\n",
    "            coiopts_default = collator_iter_opts\n",
    "            collator_iter_opts = {}\n",
    "        else:\n",
    "            coiopts_default = COIOPTS()\n",
    "\n",
    "        dls = {}\n",
    "        for k in dsd:\n",
    "            sio = sampler_iter_opts.get(k, copy.copy(sio_default))\n",
    "            coiopts = collator_iter_opts.get(k, copy.copy(coiopts_default))\n",
    "\n",
    "            if k == \"train\":\n",
    "                sio.shuffle = True\n",
    "            else: \n",
    "                sio.batch_size *= 2\n",
    "\n",
    "            dls[k] = DataLoader.hf_dsd(dsd[k], collator, sio, coiopts)\n",
    "\n",
    "        return cls(collator, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataLoaders(['train', 'valid']),\n",
       " {'train': {'sampler_iter': <minai.sampler.SamplerIter object at 0x7f805c418810>, 'cached_batch_count': 1, 'sub_batch_size': 16, 'getitem_func': <bound method Dataset.__getitem__ of Dataset({\n",
       "      features: ['image', 'label'],\n",
       "      num_rows: 100000\n",
       "  })>, 'collate_func': <bound method HFCollate.__call__ of HFCollate(features=('image', 'label'), device=None)>, 'collate_device': None},\n",
       "  'valid': {'sampler_iter': <minai.sampler.SamplerIter object at 0x7f808c507510>, 'cached_batch_count': 1, 'sub_batch_size': 32, 'getitem_func': <bound method Dataset.__getitem__ of Dataset({\n",
       "      features: ['image', 'label'],\n",
       "      num_rows: 10000\n",
       "  })>, 'collate_func': <bound method HFCollate.__call__ of HFCollate(features=('image', 'label'), device=None)>, 'collate_device': None}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaderDict.hf(dsd, COPTS(num_threads=4))\n",
    "dls, {k: dls[k].opts for k in dls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing minai_nbs/datasets.ipynb -> minai/minai/datasets.py  |  same contents, skipping, took 0.001s\n",
      "Processing minai_nbs/sampler.ipynb -> minai/minai/sampler.py  |  same contents, skipping, took 0.001s\n",
      "Processing minai_nbs/setup+template.py -> minai/setup.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/__init__+template.py -> minai/minai/__init__.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/plot.ipynb -> minai/minai/plot.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/mintils.py -> minai/minai/mintils.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/data.ipynb -> minai/minai/data.py  |  same contents, skipping, took 0.000s\n",
      "\n",
      "All done... took 0.004s\n",
      "  lib_name: minai\n",
      "  author: nblzv\n",
      "  version: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "import z_export\n",
    "z_export.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
