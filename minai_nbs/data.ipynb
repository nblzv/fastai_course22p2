{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "from minai.sampler import chunkify, Sampler, SamplerIter\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class CollatorCTX:\n",
    "    def __init__(self, sampler_iter, work_chunk_size, getitem_func, collate_func, max_available_batches):\n",
    "        self.DEBUG = 0\n",
    "        self.exit_requested = False\n",
    "\n",
    "        self.sampler_iter = sampler_iter\n",
    "        self.work_chunk_size = work_chunk_size\n",
    "        self.collate_func = collate_func\n",
    "        self.max_available_batches = max_available_batches\n",
    "\n",
    "        self.request_batch_event = threading.BoundedSemaphore(self.max_available_batches)\n",
    "        self.collated_batches = queue.SimpleQueue()\n",
    "\n",
    "        self.workers = []\n",
    "        self.getitem_func = getitem_func\n",
    "        self.indices_queue = queue.SimpleQueue()\n",
    "        self.results_queue = queue.SimpleQueue()\n",
    "\n",
    "        for _ in range(self.max_available_batches): self.request_batch_event.acquire()\n",
    "        \n",
    "\n",
    "def threadproc_worker(ctx: CollatorCTX):\n",
    "    while 1:\n",
    "        indices = ctx.indices_queue.get()\n",
    "        if indices is None: break\n",
    "        work_ind, indices = indices\n",
    "\n",
    "        results = [ctx.getitem_func(i) for i in indices]\n",
    "        ctx.results_queue.put((work_ind, results))\n",
    "        del results\n",
    "\n",
    "def threadproc_collator(ctx: CollatorCTX):\n",
    "    while 1:\n",
    "        if ctx.DEBUG: print(\"batches top\")\n",
    "        ctx.request_batch_event.acquire()\n",
    "        if ctx.exit_requested: break\n",
    "        if ctx.DEBUG: print(\"batches start\")\n",
    "\n",
    "        for batch in ctx.sampler_iter:\n",
    "            work_chunks = chunkify(batch, ctx.work_chunk_size)\n",
    "            if ctx.DEBUG: print(\"will queue\", len(work_chunks))\n",
    "            for ind, work_chunk in enumerate(work_chunks):\n",
    "                if ctx.DEBUG: print(\"put\", len(work_chunk), work_chunk)\n",
    "                ctx.indices_queue.put((ind, work_chunk))\n",
    "\n",
    "            work_chunks_results = []\n",
    "            for _ in range(len(work_chunks)):\n",
    "                ind, results = ctx.results_queue.get()\n",
    "                if ctx.DEBUG: print(\"got\", len(results), results)\n",
    "                work_chunks_results.append((ind, results))\n",
    "\n",
    "            sorted_work_chunks_results = []\n",
    "            work_chunks_results.sort(key=lambda x: x[0])\n",
    "            for work_chunk_result in work_chunks_results:\n",
    "                sorted_work_chunks_results.extend(work_chunk_result[1])\n",
    "\n",
    "            if ctx.DEBUG: print(\"collating\", len(sorted_work_chunks_results), sorted_work_chunks_results)\n",
    "            ctx.collated_batches.put(ctx.collate_func(sorted_work_chunks_results))\n",
    "            ctx.request_batch_event.acquire()\n",
    "\n",
    "        if ctx.DEBUG: print(\"batches done\")\n",
    "        for _ in range(ctx.max_available_batches-1): ctx.request_batch_event.acquire()\n",
    "        ctx.collated_batches.put(None)\n",
    "\n",
    "\n",
    "class CollatorMT:\n",
    "    def __init__(self, sampler_iter: SamplerIter, getitem_func, collate_func, *, num_workers=os.cpu_count(), max_available_batches=2, chunk_size_per_thread=4):\n",
    "        self.DEBUG = 0\n",
    "\n",
    "        work_chunk_size = max(4, sampler_iter.batch_size // (num_workers * chunk_size_per_thread))\n",
    "        if work_chunk_size * num_workers > sampler_iter.batch_size:\n",
    "            new_num_workers = max(1, math.ceil(sampler_iter.batch_size / work_chunk_size))\n",
    "            print(f\"Number of workers reduced from {num_workers} to {new_num_workers}, since num_workers*work_chunk_size > batch_size ({num_workers}*{work_chunk_size} > {sampler_iter.batch_size})\")\n",
    "            num_workers = new_num_workers\n",
    "\n",
    "        self.num_workers = num_workers\n",
    "        self.ctx = CollatorCTX(sampler_iter, work_chunk_size, getitem_func, collate_func, max_available_batches)\n",
    "\n",
    "        threading.Thread(target=threadproc_collator, args=(self.ctx,)).start()\n",
    "        for _ in range(num_workers): threading.Thread(target=threadproc_worker, args=(self.ctx,)).start()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.ctx.exit_requested = True\n",
    "        self.ctx.request_batch_event.release()\n",
    "\n",
    "        for _ in range(self.num_workers): self.ctx.indices_queue.put(None)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.ctx.request_batch_event.release(self.ctx.max_available_batches)\n",
    "        \n",
    "        while 1:\n",
    "            if self.DEBUG: print(\"-> iter request\")\n",
    "            collated = self.ctx.collated_batches.get()\n",
    "            if collated is None: \n",
    "                if self.DEBUG: print(\"-> iter done\")\n",
    "                break\n",
    "\n",
    "            if self.DEBUG: print(\"-> iter got\")\n",
    "\n",
    "            yield collated\n",
    "            self.ctx.request_batch_event.release()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers reduced from 15 to 4, since num_workers*work_chunk_size > batch_size (15*4 > 13)\n",
      "-------- ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144])\n",
      "-------- ([13, 12, 4, 2, 12, 5, 3, 3, 3, 7, 11, 7, 12], [169, 144, 16, 4, 144, 25, 9, 9, 9, 49, 121, 49, 144])\n",
      "agane\n",
      "-------- ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144])\n",
      "-------- ([13, 6, 0, 1, 12, 9, 12, 12, 6, 3, 9, 3, 0], [169, 36, 0, 1, 144, 81, 144, 144, 36, 9, 81, 9, 0])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def ds_getitem(i):\n",
    "    time.sleep(0.1)\n",
    "    return (i, i**2)\n",
    "\n",
    "def collate(results):\n",
    "    xs = [r[0] for r in results]\n",
    "    ys = [r[1] for r in results]\n",
    "    return xs, ys\n",
    "\n",
    "sampler = Sampler(14)\n",
    "batch_size = 13\n",
    "collator = CollatorMT(sampler.iter(batch_size), ds_getitem, collate, max_available_batches=2)\n",
    "\n",
    "for collated in collator:\n",
    "    print(\"--------\",collated)\n",
    "\n",
    "print(\"agane\")\n",
    "\n",
    "for collated in collator:\n",
    "    print(\"--------\",collated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class Dataset:\n",
    "    def __init__(self, xs, ys):\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        assert len(xs) == len(ys)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        assert type(i) is int\n",
    "        return self.xs[i], self.ys[i]\n",
    "    \n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle, collate_func, **kwargs):\n",
    "        self.sampler_iter = Sampler(len(dataset)).iter(batch_size, shuffle)\n",
    "        self.collator = CollatorMT(self.sampler_iter, dataset.__getitem__, collate_func, **kwargs)\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from self.collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers reduced from 15 to 4, since num_workers*work_chunk_size > batch_size (15*4 > 16)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 13, 12, 52, 52, 39, 32, 12, 25, 65, 60, 16, 76] [-96, -97, -98, -99, -13, -12, -52, -52, -39, -32, -12, -25, -65, -60, -16, -76]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 65, 11, 14, 13, 82, 24, 62, 52, 84, 36, 33, 52] [-96, -97, -98, -99, -65, -11, -14, -13, -82, -24, -62, -52, -84, -36, -33, -52]\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(list(range(100)), list(range(0, -100, -1)))\n",
    "dl = DataLoader(ds, 16, False, collate)\n",
    "\n",
    "for _ in range(2):\n",
    "    for xs, ys in dl:\n",
    "        print(xs, ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing minai_nbs/datasets.ipynb -> minai/minai/datasets.py\n",
      "  same contents, skipping, took 0.001s\n",
      "Processing minai_nbs/sampler.ipynb -> minai/minai/sampler.py\n",
      "  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/setup+template.py -> minai/setup.py\n",
      "  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/__init__+template.py -> minai/minai/__init__.py\n",
      "  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/plot.ipynb -> minai/minai/plot.py\n",
      "  nothing to export, took 0.000s\n",
      "Processing minai_nbs/mintils.py -> minai/minai/mintils.py\n",
      "  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/data.ipynb -> minai/minai/data.py\n",
      "  same contents, skipping, took 0.000s\n",
      "\n",
      "All done... took 0.003s\n",
      "  lib_name: minai\n",
      "  author: nblzv\n",
      "  version: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "import z_export\n",
    "z_export.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
