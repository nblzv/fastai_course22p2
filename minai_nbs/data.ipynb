{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "import threading\n",
    "import queue\n",
    "import os\n",
    "import math\n",
    "\n",
    "import datasets as hfds\n",
    "\n",
    "from minai.sampler import chunkify, Sampler, SamplerIter, SIO\n",
    "from minai.datasets import SimpleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class CMTO: # CollatorMTOpts\n",
    "    def __init__(self, \n",
    "                 sampler_iter: SamplerIter = None, \n",
    "                 getitem_func=None, \n",
    "                 collate_func=None, \n",
    "                 num_workers=os.cpu_count(), \n",
    "                 max_available_batches=2, \n",
    "                 chunk_size_per_thread=4,\n",
    "                 is_hf_ds=False):\n",
    "        \n",
    "        self.sampler_iter = sampler_iter\n",
    "        self.getitem_func = getitem_func\n",
    "        self.collate_func = collate_func\n",
    "        self.num_workers = num_workers\n",
    "        self.max_available_batches = max_available_batches\n",
    "        self.chunk_size_per_thread = chunk_size_per_thread\n",
    "        self.is_hf_ds = is_hf_ds\n",
    "\n",
    "        # Extra special flags, gotta be set very manually\n",
    "        self.COLLATOR_DEBUG = False\n",
    "        self.WORKERS_DEBUG = False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"CMTO({self.sampler_iter.opts},\\n\"\\\n",
    "            f\"  getitem_func={self.getitem_func.__qualname__},\\n\"\\\n",
    "            f\"  collate_func={self.collate_func.__qualname__},\\n\"\\\n",
    "            f\"  num_workers={self.num_workers},\\n\"\\\n",
    "            f\"  max_available_batches={self.max_available_batches},\\n\"\\\n",
    "            f\"  chunk_size_per_thread={self.chunk_size_per_thread},\\n\"\\\n",
    "            f\"  is_hf_ds={self.is_hf_ds})\"\n",
    "\n",
    "\n",
    "class CollatorCTX: # Internal\n",
    "    def __init__(self, opts: CMTO, work_chunk_size):\n",
    "        self.DEBUG = opts.WORKERS_DEBUG\n",
    "\n",
    "        self.sampler_iter = opts.sampler_iter\n",
    "        self.getitem_func = opts.getitem_func\n",
    "        self.collate_func = opts.collate_func\n",
    "        self.max_available_batches = opts.max_available_batches\n",
    "        self.is_hf_ds = opts.is_hf_ds\n",
    "        self.work_chunk_size = work_chunk_size\n",
    "\n",
    "        self.workers = []\n",
    "        self.indices_queue = queue.SimpleQueue()\n",
    "        self.results_queue = queue.SimpleQueue()\n",
    "        \n",
    "        self.request_batch_event = threading.BoundedSemaphore(self.max_available_batches)\n",
    "        self.collated_batches = queue.SimpleQueue()\n",
    "        self.exit_requested = False\n",
    "\n",
    "        for _ in range(self.max_available_batches): self.request_batch_event.acquire()\n",
    "\n",
    "\n",
    "def threadproc_worker(ctx: CollatorCTX):\n",
    "    while 1:\n",
    "        indices = ctx.indices_queue.get()\n",
    "        if indices is None: break\n",
    "        work_ind, indices = indices\n",
    "\n",
    "        if ctx.is_hf_ds:\n",
    "            results = ctx.getitem_func(indices)\n",
    "        else:\n",
    "            results = [ctx.getitem_func(i) for i in indices]\n",
    "\n",
    "        ctx.results_queue.put((work_ind, results))\n",
    "        del results\n",
    "\n",
    "def threadproc_collator(ctx: CollatorCTX):\n",
    "    while 1:\n",
    "        if ctx.DEBUG: print(\"batches top\")\n",
    "        \n",
    "        ctx.request_batch_event.acquire()\n",
    "        if ctx.exit_requested: break\n",
    "        \n",
    "        if ctx.DEBUG: print(\"batches start\")\n",
    "        for batch in ctx.sampler_iter:\n",
    "            work_chunks = chunkify(batch, ctx.work_chunk_size)\n",
    "            if ctx.DEBUG: print(\"will queue\", len(work_chunks))\n",
    "            for ind, work_chunk in enumerate(work_chunks):\n",
    "                if ctx.DEBUG: print(ind, \"put\", len(work_chunk), work_chunk)\n",
    "                ctx.indices_queue.put((ind, work_chunk))\n",
    "\n",
    "            work_chunks_results = []\n",
    "            for _ in range(len(work_chunks)):\n",
    "                ind, results = ctx.results_queue.get()\n",
    "                if ctx.DEBUG: print(ind, \"got\", len(results), results)\n",
    "                work_chunks_results.append((ind, results))\n",
    "\n",
    "            work_chunks_results.sort(key=lambda x: x[0])\n",
    "\n",
    "            sorted_work_chunks_results = []\n",
    "            if ctx.is_hf_ds: # SOA\n",
    "                sorted_work_chunks_results = [x[1] for x in work_chunks_results]\n",
    "            else:\n",
    "                for work_chunk_result in work_chunks_results: # AOS\n",
    "                    sorted_work_chunks_results.extend(work_chunk_result[1])\n",
    "            \n",
    "            del work_chunks_results\n",
    "\n",
    "            ctx.collated_batches.put(ctx.collate_func(sorted_work_chunks_results))\n",
    "            ctx.request_batch_event.acquire()\n",
    "            if ctx.exit_requested: break # Double break\n",
    "\n",
    "        if ctx.exit_requested: break # Double break\n",
    "        if ctx.DEBUG: print(\"batches done\")\n",
    "        for _ in range(ctx.max_available_batches-1): ctx.request_batch_event.acquire()\n",
    "        ctx.collated_batches.put(None)\n",
    "\n",
    "    #if ctx.DEBUG: print(\"collator exit\")\n",
    "\n",
    "\n",
    "class CollatorMT:\n",
    "    def __init__(self, collatormt_opts: CMTO):\n",
    "        self.DEBUG = collatormt_opts.COLLATOR_DEBUG\n",
    "        self.opts = collatormt_opts\n",
    "\n",
    "        batch_size = self.opts.sampler_iter.opts.batch_size\n",
    "        chunk_size_per_thread = self.opts.chunk_size_per_thread\n",
    "        num_workers = self.opts.num_workers\n",
    "        work_chunk_size = max(chunk_size_per_thread, \n",
    "                              batch_size // (num_workers * chunk_size_per_thread))\n",
    "\n",
    "        new_num_workers = min(max(1, math.ceil(batch_size / work_chunk_size)), num_workers)\n",
    "        if new_num_workers != num_workers:\n",
    "            print(f\"Number of workers reduced from {num_workers} to {new_num_workers}, since \"\\\n",
    "                  f\"num_workers*work_chunk_size > batch_size ({num_workers}*{work_chunk_size} > {batch_size})\")\n",
    "            self.opts.num_workers = new_num_workers\n",
    "\n",
    "        self.ctx = CollatorCTX(self.opts, work_chunk_size)\n",
    "\n",
    "        threading.Thread(target=threadproc_collator, args=(self.ctx,)).start()\n",
    "        for _ in range(self.opts.num_workers): threading.Thread(target=threadproc_worker, args=(self.ctx,)).start()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.ctx.exit_requested = True\n",
    "        self.ctx.request_batch_event.release()\n",
    "\n",
    "        for _ in range(self.opts.num_workers): self.ctx.indices_queue.put(None)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.ctx.request_batch_event.release(self.ctx.max_available_batches)\n",
    "        \n",
    "        while 1:\n",
    "            if self.DEBUG: print(\"-> iter request\")\n",
    "            collated = self.ctx.collated_batches.get()\n",
    "            if collated is None: \n",
    "                if self.DEBUG: print(\"-> iter done\")\n",
    "                break\n",
    "\n",
    "            if self.DEBUG: print(\"-> iter got\")\n",
    "\n",
    "            yield collated\n",
    "            self.ctx.request_batch_event.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def simple_collate_func(results):\n",
    "    xs = [r[0] for r in results]\n",
    "    ys = [r[1] for r in results]\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers reduced from 15 to 4, since num_workers*work_chunk_size > batch_size (15*4 > 13)\n",
      "-------- ([10, 4, 9, 12, 11, 1, 8, 0, 3, 13, 2, 6, 5], [100, 16, 81, 144, 121, 1, 64, 0, 9, 169, 4, 36, 25])\n",
      "-------- ([7, 2, 1, 3, 0, 4, 11, 2, 13, 13, 11, 13, 0], [49, 4, 1, 9, 0, 16, 121, 4, 169, 169, 121, 169, 0])\n",
      "agane\n",
      "-------- ([1, 7, 10, 4, 8, 12, 13, 11, 2, 3, 5, 9, 0], [1, 49, 100, 16, 64, 144, 169, 121, 4, 9, 25, 81, 0])\n",
      "-------- ([6, 9, 5, 4, 7, 6, 10, 0, 2, 4, 0, 12, 13], [36, 81, 25, 16, 49, 36, 100, 0, 4, 16, 0, 144, 169])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def ds_getitem(i):\n",
    "    time.sleep(0.1)\n",
    "    return (i, i**2)\n",
    "\n",
    "sampler = Sampler(14)\n",
    "batch_size = 13\n",
    "collator = CollatorMT(CMTO(sampler.iter(SIO(batch_size)), ds_getitem, simple_collate_func, max_available_batches=2))\n",
    "\n",
    "for collated in collator:\n",
    "    print(\"--------\",collated)\n",
    "\n",
    "print(\"agane\")\n",
    "\n",
    "for collated in collator:\n",
    "    print(\"--------\",collated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def hf_first_ds(dsd):\n",
    "    return next(iter(dsd.values()))\n",
    "\n",
    "class HFCollate:\n",
    "    def __init__(self, ds: hfds.Dataset):\n",
    "        if type(ds) is hfds.DatasetDict: ds = hf_first_ds(ds)\n",
    "        self.features = ds.features.keys()\n",
    "        self.features_len = len(self.features)\n",
    "\n",
    "    def __call__(self, results):\n",
    "        collated = [[] for _ in range(self.features_len)]\n",
    "        for result in results:\n",
    "            for i, feature in enumerate(self.features):\n",
    "                collated[i].extend(result[feature])\n",
    "        return collated\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"CollateHF(features={list(self.features)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/nblzv/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece983956d984579a17970701bab6552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import minai.datasets as minds\n",
    "fashion_mnist = minds.hf_load(minds.HF_DATASETS.FASHION_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CollateHF(features=['image', 'label'])\n",
      "[[<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FCF8BA269D0>, <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FCF8BAF1ED0>, <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FCF88C30D50>], [9, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "c = HFCollate(fashion_mnist)\n",
    "print(c)\n",
    "print(c([fashion_mnist[\"train\"][[0, 1]], fashion_mnist[\"train\"][[2]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, collatormt_opts:CMTO):\n",
    "        self.dataset = dataset\n",
    "        self.collator = CollatorMT(collatormt_opts)\n",
    "\n",
    "    @classmethod\n",
    "    def simple(cls, simple_ds: SimpleDataset, \n",
    "               sampler_iter_opts: SIO = None, \n",
    "               collatormt_opts: CMTO = None):\n",
    "        sampler_iter_opts = sampler_iter_opts or SIO()\n",
    "        collatormt_opts = collatormt_opts or CMTO()\n",
    "\n",
    "        opts = collatormt_opts\n",
    "        opts.sampler_iter = Sampler(len(simple_ds)).iter(sampler_iter_opts)\n",
    "        opts.getitem_func = simple_ds.__getitem__\n",
    "        opts.collate_func = simple_collate_func\n",
    "        return cls(simple_ds, opts)\n",
    "\n",
    "    @classmethod\n",
    "    def hf(cls, hf_ds: hfds.Dataset,\n",
    "           sampler_iter_opts: SIO = None, \n",
    "           collatormt_opts: CMTO = None):\n",
    "        assert type(hf_ds) is hfds.Dataset, \"Dataset expected (not DatasetDict)\"\n",
    "        sampler_iter_opts = sampler_iter_opts or SIO()\n",
    "        collatormt_opts = collatormt_opts or CMTO()\n",
    "\n",
    "        opts = collatormt_opts\n",
    "        opts.sampler_iter = Sampler(len(hf_ds)).iter(sampler_iter_opts)\n",
    "        opts.getitem_func = hf_ds.__getitem__\n",
    "        opts.collate_func = HFCollate(hf_ds).__call__\n",
    "        opts.is_hf_ds = True\n",
    "        return cls(hf_ds, opts)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        yield from self.collator\n",
    "\n",
    "    def __repr__(self):\n",
    "        ctmo = self.collator.opts.__repr__()\n",
    "        ctmo = ctmo.replace(\"\\n\", \"\\n  \")\n",
    "\n",
    "        return f\"DataLoader(ds={self.dataset},\\n  {ctmo})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers reduced from 15 to 4, since num_workers*work_chunk_size > batch_size (15*4 > 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SimpleDataset(len=100, xs=int, ys=int),\n",
       " DataLoader(ds=SimpleDataset(len=100, xs=int, ys=int),\n",
       "   CMTO(SIO(batch_size=16, shuffle=False, drop_last=False),\n",
       "     getitem_func=SimpleDataset.__getitem__,\n",
       "     collate_func=simple_collate_func,\n",
       "     num_workers=4,\n",
       "     max_available_batches=2,\n",
       "     chunk_size_per_thread=4,\n",
       "     is_hf_ds=False)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = SimpleDataset(list(range(100)), list(range(0, -100, -1)))\n",
    "dl = DataLoader.simple(ds, SIO(16, False))\n",
    "ds, dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 17, 92, 70, 38, 9, 60, 82, 68, 44, 61, 9, 42] [-96, -97, -98, -99, -17, -92, -70, -38, -9, -60, -82, -68, -44, -61, -9, -42]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 78, 4, 41, 23, 12, 36, 54, 99, 84, 52, 64, 44] [-96, -97, -98, -99, -78, -4, -41, -23, -12, -36, -54, -99, -84, -52, -64, -44]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    for xs, ys in dl:\n",
    "        print(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers reduced from 15 to 3, since num_workers*work_chunk_size > batch_size (15*4 > 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DataLoader(ds=Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 60000\n",
       " }),\n",
       "   CMTO(SIO(batch_size=9, shuffle=False, drop_last=False),\n",
       "     getitem_func=Dataset.__getitem__,\n",
       "     collate_func=HFCollate.__call__,\n",
       "     num_workers=3,\n",
       "     max_available_batches=1,\n",
       "     chunk_size_per_thread=4,\n",
       "     is_hf_ds=True)),\n",
       " [[<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>],\n",
       "  [9, 0, 0, 3, 0, 2, 7, 2, 5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader.hf(fashion_mnist[\"train\"], SIO(9, False), CMTO(max_available_batches=1))\n",
    "dl, next(iter(dl.collator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing minai_nbs/datasets.ipynb -> minai/minai/datasets.py  |  same contents, skipping, took 0.001s\n",
      "Processing minai_nbs/sampler.ipynb -> minai/minai/sampler.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/setup+template.py -> minai/setup.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/__init__+template.py -> minai/minai/__init__.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/plot.ipynb -> minai/minai/plot.py  |  nothing to export, took 0.000s\n",
      "Processing minai_nbs/mintils.py -> minai/minai/mintils.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/data.ipynb -> minai/minai/data.py  |  5 cells exported, took 0.000s \n",
      "\n",
      "All done... took 0.002s\n",
      "  lib_name: minai\n",
      "  author: nblzv\n",
      "  version: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "import z_export\n",
    "z_export.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
