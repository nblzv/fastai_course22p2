{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "import threading\n",
    "import queue\n",
    "import os\n",
    "import math\n",
    "\n",
    "import datasets as hfds\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.io as TFIO\n",
    "\n",
    "from minai.sampler import chunkify, Sampler, SamplerIter, SIO\n",
    "from minai.datasets import SimpleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class CMTO: # CollatorMTOpts\n",
    "    def __init__(self, \n",
    "                 sampler_iter: SamplerIter = None, \n",
    "                 getitem_func=None, \n",
    "                 collate_func=None, \n",
    "                 num_workers=os.cpu_count(), \n",
    "                 max_available_batches=2, \n",
    "                 chunk_size_per_thread=4,\n",
    "                 is_hf_ds=False):\n",
    "        \n",
    "        self.sampler_iter = sampler_iter\n",
    "        self.getitem_func = getitem_func\n",
    "        self.collate_func = collate_func\n",
    "        self.num_workers = num_workers\n",
    "        self.max_available_batches = max_available_batches\n",
    "        self.chunk_size_per_thread = chunk_size_per_thread\n",
    "        self.is_hf_ds = is_hf_ds\n",
    "\n",
    "        # Extra special flags, gotta be set very manually\n",
    "        self.COLLATOR_DEBUG = False\n",
    "        self.WORKERS_DEBUG = False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"CMTO({self.sampler_iter.opts},\\n\"\\\n",
    "            f\"    getitem_func={self.getitem_func.__qualname__},\\n\"\\\n",
    "            f\"    collate_func={self.collate_func.__qualname__},\\n\"\\\n",
    "            f\"    num_workers={self.num_workers},\\n\"\\\n",
    "            f\"    max_available_batches={self.max_available_batches},\\n\"\\\n",
    "            f\"    chunk_size_per_thread={self.chunk_size_per_thread},\\n\"\\\n",
    "            f\"    is_hf_ds={self.is_hf_ds})\"\n",
    "\n",
    "\n",
    "class CollatorCTX: # Internal\n",
    "    def __init__(self, opts: CMTO, work_chunk_size):\n",
    "        self.DEBUG = opts.WORKERS_DEBUG\n",
    "\n",
    "        self.sampler_iter = opts.sampler_iter\n",
    "        self.getitem_func = opts.getitem_func\n",
    "        self.collate_func = opts.collate_func\n",
    "        self.max_available_batches = opts.max_available_batches\n",
    "        self.is_hf_ds = opts.is_hf_ds\n",
    "        self.work_chunk_size = work_chunk_size\n",
    "\n",
    "        self.workers = []\n",
    "        self.indices_queue = queue.SimpleQueue()\n",
    "        self.results_queue = queue.SimpleQueue()\n",
    "        \n",
    "        self.request_batch_event = threading.Semaphore(self.max_available_batches)\n",
    "        self.collated_batches = queue.SimpleQueue()\n",
    "        self.exit_requested = False\n",
    "        self.new_iter_requested = False\n",
    "\n",
    "        for _ in range(self.max_available_batches): self.request_batch_event.acquire()\n",
    "\n",
    "\n",
    "def threadproc_worker(ctx: CollatorCTX):\n",
    "    while 1:\n",
    "        indices = ctx.indices_queue.get()\n",
    "        if indices is None: break\n",
    "        work_ind, indices = indices\n",
    "\n",
    "        if ctx.is_hf_ds:\n",
    "            results = ctx.getitem_func(indices)\n",
    "        else:\n",
    "            results = [ctx.getitem_func(i) for i in indices]\n",
    "\n",
    "        ctx.results_queue.put((work_ind, results))\n",
    "        del results\n",
    "\n",
    "def threadproc_collator(ctx: CollatorCTX):\n",
    "    last_iter_finished = True\n",
    "\n",
    "    while 1:\n",
    "        if ctx.DEBUG: print(\"batches top\")\n",
    "        \n",
    "        if last_iter_finished: \n",
    "            ctx.request_batch_event.acquire()\n",
    "\n",
    "        if ctx.exit_requested: break\n",
    "        ctx.new_iter_requested = False\n",
    "        last_iter_finished = True\n",
    "        \n",
    "        if ctx.DEBUG: print(\"batches start\")\n",
    "        for batch in ctx.sampler_iter:\n",
    "            work_chunks = chunkify(batch, ctx.work_chunk_size)\n",
    "            if ctx.DEBUG: print(\"will queue\", len(work_chunks))\n",
    "            for ind, work_chunk in enumerate(work_chunks):\n",
    "                if ctx.DEBUG: print(ind, \"put\", len(work_chunk), work_chunk)\n",
    "                ctx.indices_queue.put((ind, work_chunk))\n",
    "\n",
    "            work_chunks_results = []\n",
    "            for _ in range(len(work_chunks)):\n",
    "                ind, results = ctx.results_queue.get()\n",
    "                if ctx.DEBUG: print(ind, \"got\", len(results), results)\n",
    "                work_chunks_results.append((ind, results))\n",
    "\n",
    "            work_chunks_results.sort(key=lambda x: x[0])\n",
    "\n",
    "            sorted_work_chunks_results = []\n",
    "            if ctx.is_hf_ds: # SOA\n",
    "                sorted_work_chunks_results = [x[1] for x in work_chunks_results]\n",
    "            else:\n",
    "                for work_chunk_result in work_chunks_results: # AOS\n",
    "                    sorted_work_chunks_results.extend(work_chunk_result[1])\n",
    "            \n",
    "            del work_chunks_results\n",
    "\n",
    "            ctx.collated_batches.put(ctx.collate_func(sorted_work_chunks_results))\n",
    "            ctx.request_batch_event.acquire()\n",
    "            \n",
    "            if ctx.exit_requested: last_iter_finished = False; break # Double break\n",
    "            if ctx.new_iter_requested: last_iter_finished = False; break\n",
    "\n",
    "        if ctx.exit_requested: break # Double break\n",
    "        \n",
    "        ctx.collated_batches.put(None)\n",
    "        if last_iter_finished:\n",
    "            for _ in range(ctx.max_available_batches-1): ctx.request_batch_event.acquire()\n",
    "\n",
    "        if ctx.new_iter_requested:\n",
    "            ctx.new_iter_requested = False\n",
    "            if ctx.DEBUG: print(\"batches restart\")\n",
    "        else:\n",
    "            if ctx.DEBUG: print(\"batches done\")\n",
    "\n",
    "    if ctx.DEBUG > 1: print(\"collator exit\")\n",
    "\n",
    "\n",
    "class CollatorMT:\n",
    "    def __init__(self, collatormt_opts: CMTO):\n",
    "        self.DEBUG = collatormt_opts.COLLATOR_DEBUG\n",
    "        self.opts = collatormt_opts\n",
    "\n",
    "        batch_size = self.opts.sampler_iter.opts.batch_size\n",
    "        chunk_size_per_thread = self.opts.chunk_size_per_thread\n",
    "        num_workers = self.opts.num_workers\n",
    "        work_chunk_size = max(chunk_size_per_thread, \n",
    "                              batch_size // (num_workers * chunk_size_per_thread))\n",
    "\n",
    "        new_num_workers = min(max(1, math.ceil(batch_size / work_chunk_size)), num_workers)\n",
    "        if new_num_workers != num_workers:\n",
    "            if self.DEBUG:\n",
    "                print(f\"Number of workers reduced from {num_workers} to {new_num_workers}, since \"\\\n",
    "                      f\"num_workers*work_chunk_size > batch_size ({num_workers}*{work_chunk_size} > {batch_size})\")\n",
    "            self.opts.num_workers = new_num_workers\n",
    "\n",
    "        max_available_batches = self.opts.max_available_batches\n",
    "        num_batches = self.opts.sampler_iter.num_batches\n",
    "        new_max_available_batches = min(max_available_batches, num_batches)\n",
    "        if new_max_available_batches != max_available_batches:\n",
    "            if self.DEBUG:\n",
    "                print(f\"Max available batches reduced from {max_available_batches} to {new_max_available_batches}\")\n",
    "            self.opts.max_available_batches = new_max_available_batches\n",
    "\n",
    "        self.ctx = CollatorCTX(self.opts, work_chunk_size)\n",
    "        self.last_iter_finished = True\n",
    "        self.threads_spawned = False\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.DEBUG > 1: print(\"-> collator del\")\n",
    "        \n",
    "        self.ctx.exit_requested = True\n",
    "        self.ctx.request_batch_event.release()\n",
    "\n",
    "        for _ in range(self.opts.num_workers): self.ctx.indices_queue.put(None)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.ctx.new_iter_requested = True\n",
    "        self.ctx.request_batch_event.release(self.ctx.max_available_batches)\n",
    "        \n",
    "        if not self.last_iter_finished:\n",
    "            while self.ctx.collated_batches.get() is not None: \n",
    "                pass # Consume the remaining cached batches before restarting\n",
    "        self.last_iter_finished = False\n",
    "        \n",
    "        if not self.threads_spawned:\n",
    "            threading.Thread(target=threadproc_collator, args=(self.ctx,)).start()\n",
    "            for _ in range(self.opts.num_workers): threading.Thread(target=threadproc_worker, args=(self.ctx,)).start()\n",
    "            self.threads_spawned = True\n",
    "\n",
    "        while 1:\n",
    "            if self.DEBUG: print(\"-> iter request\")\n",
    "            collated = self.ctx.collated_batches.get()\n",
    "            if collated is None: \n",
    "                self.last_iter_finished = True\n",
    "                if self.DEBUG: print(\"-> iter done\")\n",
    "                break\n",
    "\n",
    "            if self.DEBUG: print(\"-> iter got\")\n",
    "            yield collated\n",
    "\n",
    "            self.ctx.request_batch_event.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def simple_collate_func(results):\n",
    "    xs = [r[0] for r in results]\n",
    "    ys = [r[1] for r in results]\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def ds_getitem(i):\n",
    "    time.sleep(0.1)\n",
    "    return (i, -i)\n",
    "\n",
    "sampler = Sampler(17)\n",
    "batch_size = 16\n",
    "collator = CollatorMT(CMTO(sampler.iter(SIO(batch_size)), \n",
    "                           ds_getitem, \n",
    "                           simple_collate_func, \n",
    "                           max_available_batches=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15])\n",
      "([16, 8, 12, 3, 15, 1, 0, 9, 10, 16, 0, 5, 14, 1, 3, 2], [-16, -8, -12, -3, -15, -1, 0, -9, -10, -16, 0, -5, -14, -1, -3, -2])\n",
      "agane\n",
      "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15])\n",
      "([16, 10, 8, 1, 16, 10, 0, 0, 14, 10, 6, 8, 13, 15, 11, 1], [-16, -10, -8, -1, -16, -10, 0, 0, -14, -10, -6, -8, -13, -15, -11, -1])\n"
     ]
    }
   ],
   "source": [
    "for collated in collator:\n",
    "    print(collated)\n",
    "\n",
    "print(\"agane\")\n",
    "\n",
    "for collated in collator:\n",
    "    print(collated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class HFCollate:\n",
    "    def __init__(self, ds: hfds.Dataset):\n",
    "        self.features = tuple(ds.features.keys())\n",
    "\n",
    "    def __call__(self, results):\n",
    "        collated = [[] for _ in range(len(self.features))]\n",
    "        for result in results:\n",
    "            for i, feature in enumerate(self.features):\n",
    "                collated[i].extend(result[feature])\n",
    "        return collated\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"HFCollate(features={self.features})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/nblzv/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8483af4632a14a88bf63dfb7a865879d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import minai.datasets as minds\n",
    "dsd = minds.hf_load(minds.HF_DATASETS.FASHION_MNIST)\n",
    "dst = dsd[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HFCollate(features=('image', 'label'))\n",
      "[[<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FC8E04D3F50>, <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FC8C8FDF410>, <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FC8C8FF0290>], [9, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "c = HFCollate(dst)\n",
    "print(c)\n",
    "print(c([dst[[0, 1]], dst[[2]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, collatormt_opts:CMTO):\n",
    "        self.ds = dataset\n",
    "        self.collator = CollatorMT(collatormt_opts)\n",
    "\n",
    "    @classmethod\n",
    "    def simple(cls, simple_ds: SimpleDataset, sampler_iter_opts: SIO = None, collatormt_opts: CMTO = None):\n",
    "        sampler_iter_opts = sampler_iter_opts or SIO()\n",
    "        collatormt_opts = collatormt_opts or CMTO()\n",
    "\n",
    "        opts = collatormt_opts\n",
    "        opts.sampler_iter = Sampler(len(simple_ds)).iter(sampler_iter_opts)\n",
    "        opts.getitem_func = simple_ds.__getitem__\n",
    "        opts.collate_func = simple_collate_func\n",
    "        return cls(simple_ds, opts)\n",
    "\n",
    "    @classmethod\n",
    "    def hf(cls, hf_ds: hfds.Dataset, sampler_iter_opts: SIO = None, collatormt_opts: CMTO = None):\n",
    "        assert type(hf_ds) is hfds.Dataset, f\"Dataset expected, not {type(hf_ds).__name__}\"\n",
    "        sampler_iter_opts = sampler_iter_opts or SIO()\n",
    "        collatormt_opts = collatormt_opts or CMTO()\n",
    "\n",
    "        opts = collatormt_opts\n",
    "        opts.sampler_iter = Sampler(len(hf_ds)).iter(sampler_iter_opts)\n",
    "        opts.getitem_func = hf_ds.__getitem__\n",
    "        opts.collate_func = HFCollate(hf_ds).__call__\n",
    "        opts.is_hf_ds = True\n",
    "        return cls(hf_ds, opts)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        yield from self.collator\n",
    "\n",
    "    def __repr__(self):\n",
    "        ctmo = self.collator.opts.__repr__()\n",
    "        ctmo = ctmo.replace(\"\\n\", \"\\n    \")\n",
    "\n",
    "        return f\"DataLoader(ds={self.ds},\\n    {ctmo}\\n)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SimpleDataset(len=100, xs=int, ys=int),\n",
       " DataLoader(ds=SimpleDataset(len=100, xs=int, ys=int),\n",
       "     CMTO(SIO(batch_size=16, shuffle=False, drop_last=False),\n",
       "         getitem_func=SimpleDataset.__getitem__,\n",
       "         collate_func=simple_collate_func,\n",
       "         num_workers=4,\n",
       "         max_available_batches=7,\n",
       "         chunk_size_per_thread=4,\n",
       "         is_hf_ds=False)\n",
       " ))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = SimpleDataset(list(range(100)), list(range(0, -100, -1)))\n",
    "dl = DataLoader.simple(ds, SIO(16), CMTO(max_available_batches=10))\n",
    "ds, dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15])\n",
      "([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31])\n",
      "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15])\n",
      "([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31])\n"
     ]
    }
   ],
   "source": [
    "it = iter(dl)\n",
    "print(next(it))\n",
    "print(next(it))\n",
    "\n",
    "it = iter(dl)\n",
    "print(next(it))\n",
    "print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 61, 84, 93, 41, 98, 93, 26, 23, 95, 86, 49, 76] [-96, -97, -98, -99, -61, -84, -93, -41, -98, -93, -26, -23, -95, -86, -49, -76]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] [-16, -17, -18, -19, -20, -21, -22, -23, -24, -25, -26, -27, -28, -29, -30, -31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] [-32, -33, -34, -35, -36, -37, -38, -39, -40, -41, -42, -43, -44, -45, -46, -47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] [-48, -49, -50, -51, -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79] [-64, -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77, -78, -79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95] [-80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90, -91, -92, -93, -94, -95]\n",
      "[96, 97, 98, 99, 88, 91, 91, 87, 43, 43, 41, 28, 74, 13, 56, 16] [-96, -97, -98, -99, -88, -91, -91, -87, -43, -43, -41, -28, -74, -13, -56, -16]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    for xs, ys in dl:\n",
    "        print(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataLoader(ds=Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 60000\n",
       " }),\n",
       "     CMTO(SIO(batch_size=9, shuffle=False, drop_last=False),\n",
       "         getitem_func=Dataset.__getitem__,\n",
       "         collate_func=HFCollate.__call__,\n",
       "         num_workers=3,\n",
       "         max_available_batches=1,\n",
       "         chunk_size_per_thread=4,\n",
       "         is_hf_ds=True)\n",
       " ),\n",
       " [[<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "   <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>],\n",
       "  [9, 0, 0, 3, 0, 2, 7, 2, 5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader.hf(dst, SIO(9, False), CMTO(max_available_batches=1))\n",
    "dl, next(iter(dl.collator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class HFTransform:\n",
    "    def __init__(self, features, transform, **extra_args):\n",
    "        assert type(features) is hfds.features.features.Features\n",
    "        self.features = tuple(features)\n",
    "        self.transform = transform\n",
    "\n",
    "        for k, v in extra_args.items():\n",
    "            super().__setattr__(k ,v)\n",
    "\n",
    "    def __call__(self, results):\n",
    "        return self.transform(self, results)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"HFTransform(features={list(self.features)})\"\n",
    "\n",
    "    @classmethod\n",
    "    def ff_img_to_tensor(cls, features): # first_feature\n",
    "        def tf(ctx: HFTransform, results):\n",
    "            xs = results[ctx.features[0]]\n",
    "            for i in range(len(xs)):\n",
    "                xs[i] = TF.to_tensor(xs[i])\n",
    "            return results\n",
    "        \n",
    "        return cls(features, tf)\n",
    "    \n",
    "    @classmethod\n",
    "    def ff_img_decode_to_tensor(cls, features, half=False): # first_feature\n",
    "        def tf(ctx: HFTransform, results):\n",
    "            xs = results[ctx.features[0]]\n",
    "            for i in range(len(xs)):\n",
    "                raw = torch.frombuffer(xs[i][\"bytes\"], dtype=torch.uint8)\n",
    "                decoded = TFIO.decode_image(raw)\n",
    "                if ctx.half: decoded = decode.half()\n",
    "                else: decoded = decoded.float()\n",
    "                xs[i] = decoded / 255.0\n",
    "            return results\n",
    "        \n",
    "        return cls(features, tf, half=half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "def first(iterable):\n",
    "    return next(iter(iterable))\n",
    "\n",
    "def first_value(iterable):\n",
    "    return next(iter(iterable.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_tensor_transform(ctx, results):\n",
    "    xs = results[ctx.features[0]]\n",
    "    for i in range(len(xs)):\n",
    "        xs[i] = TF.to_tensor(xs[i])\n",
    "    return results\n",
    "\n",
    "thds = dst.with_transform(HFTransform(dst.features, to_tensor_transform))\n",
    "dl = DataLoader.hf(thds, SIO(5, False), CMTO(max_available_batches=1))\n",
    "first(dl)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624 ms ± 21.9 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "tdst = dst.with_transform(HFTransform.ff_img_to_tensor(dst.features))\n",
    "dl = DataLoader.hf(tdst, SIO(1024), collatormt_opts=CMTO(max_available_batches=1))\n",
    "%timeit -r 10 -n 1 first(dl);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20747/1456250114.py:32: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1687158866840/work/torch/csrc/utils/tensor_new.cpp:1505.)\n",
      "  raw = torch.frombuffer(xs[i][\"bytes\"], dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339 ms ± 10.7 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "tdst = dst.with_transform(HFTransform.ff_img_decode_to_tensor(dst.features)).cast_column(\"image\", hfds.Image(decode=False))\n",
    "dl = DataLoader.hf(tdst, SIO(1024), collatormt_opts=CMTO(max_available_batches=1))\n",
    "%timeit -r 10 -n 1 first(dl);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e\n",
    "class DataLoaderDict(dict):\n",
    "    def __init__(self, dataloaders_dict: dict):\n",
    "        super().__init__(dataloaders_dict)\n",
    "\n",
    "    def __getitem__(self, key) -> DataLoader:\n",
    "        return super().__getitem__(key)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"DataLoaders({super().__repr__()})\"\n",
    "\n",
    "    @classmethod\n",
    "    def hf(cls, dsd: hfds.DatasetDict, sampler_iter_opts: SIO = None, collatormt_opts: CMTO = None):\n",
    "        dls = {}\n",
    "        for k in dsd:\n",
    "            dls[k] = DataLoader.hf(dsd[k], sampler_iter_opts, collatormt_opts)\n",
    "        return cls(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoaders({'train': DataLoader(ds=Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 60000\n",
       "}),\n",
       "    CMTO(SIO(batch_size=64, shuffle=False, drop_last=False),\n",
       "        getitem_func=Dataset.__getitem__,\n",
       "        collate_func=HFCollate.__call__,\n",
       "        num_workers=15,\n",
       "        max_available_batches=2,\n",
       "        chunk_size_per_thread=4,\n",
       "        is_hf_ds=True)\n",
       "), 'test': DataLoader(ds=Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 10000\n",
       "}),\n",
       "    CMTO(SIO(batch_size=64, shuffle=False, drop_last=False),\n",
       "        getitem_func=Dataset.__getitem__,\n",
       "        collate_func=HFCollate.__call__,\n",
       "        num_workers=15,\n",
       "        max_available_batches=2,\n",
       "        chunk_size_per_thread=4,\n",
       "        is_hf_ds=True)\n",
       ")})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaderDict.hf(dsd)\n",
    "dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing minai_nbs/datasets.ipynb -> minai/minai/datasets.py  |  same contents, skipping, took 0.001s\n",
      "Processing minai_nbs/sampler.ipynb -> minai/minai/sampler.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/setup+template.py -> minai/setup.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/__init__+template.py -> minai/minai/__init__.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/plot.ipynb -> minai/minai/plot.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/mintils.py -> minai/minai/mintils.py  |  same contents, skipping, took 0.000s\n",
      "Processing minai_nbs/data.ipynb -> minai/minai/data.py  |  same contents, skipping, took 0.000s\n",
      "\n",
      "All done... took 0.004s\n",
      "  lib_name: minai\n",
      "  author: nblzv\n",
      "  version: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "import z_export\n",
    "z_export.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
